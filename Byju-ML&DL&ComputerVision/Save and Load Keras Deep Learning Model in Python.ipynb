{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa7a7f7d",
   "metadata": {},
   "source": [
    "# Save and Load Your Keras Deep Learning Model\n",
    "https://machinelearningmastery.com/save-load-keras-deep-learning-models/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b8701c6",
   "metadata": {},
   "source": [
    "Keras is a simple and powerful Python library for deep learning.\n",
    "\n",
    "Given that deep learning models can take hours, days and even weeks to train, it is important to know how to save and load them from disk.\n",
    "\n",
    "In this post, you will discover how you can save your Keras models to file and load them up again to make predictions.\n",
    "\n",
    "After reading this tutorial you will know:\n",
    "\n",
    "How to save model weights and model architecture in separate files.\n",
    "How to save model architecture in both YAML and JSON format.\n",
    "How to save model weights and architecture into a single file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd884264",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tutorial Overview"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b51e7236",
   "metadata": {},
   "source": [
    "If you are new to Keras or deep learning, see this step-by-step Keras tutorial.\n",
    "\n",
    "Keras separates the concerns of saving your model architecture and saving your model weights.\n",
    "\n",
    "Model weights are saved to HDF5 format. This is a grid format that is ideal for storing multi-dimensional arrays of numbers.\n",
    "\n",
    "The model structure can be described and saved using two different formats: JSON and YAML.\n",
    "\n",
    "In this post we are going to look at three examples of saving and loading your model to file:\n",
    "\n",
    "Save Model to JSON.\n",
    "Save Model to YAML.\n",
    "Save Model to HDF5.\n",
    "\n",
    "The first two examples save the model architecture and weights separately. The model weights are saved into a HDF5 format file in all cases.\n",
    "\n",
    "The examples will use the same simple network trained on the Pima Indians onset of diabetes binary classification dataset. This is a small dataset that contains all numerical data and is easy to work with. You can download this dataset and place it in your working directory with the filename “pima-indians-diabetes.csv” (update: download from here).\n",
    "\n",
    "Confirm that you have TensorFlow v2.x installed (e.g. v2.9 as of June 2022).\n",
    "\n",
    "Note: Saving models requires that you have the h5py library installed. It is usually installed as a dependency with TensorFlow. You can also install it easily as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a47b9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: h5py in c:\\users\\byju\\anaconda3\\lib\\site-packages (2.10.0)\n",
      "Requirement already satisfied: six in c:\\users\\byju\\anaconda3\\lib\\site-packages (from h5py) (1.15.0)\n",
      "Requirement already satisfied: numpy>=1.7 in c:\\users\\byju\\anaconda3\\lib\\site-packages (from h5py) (1.20.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18a5faa",
   "metadata": {},
   "source": [
    "# Save Your Neural Network Model to JSON"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cb7814f",
   "metadata": {},
   "source": [
    "\n",
    "JSON is a simple file format for describing data hierarchically.\n",
    "\n",
    "Keras provides the ability to describe any model using JSON format with a to_json() function. This can be saved to file and later loaded via the model_from_json() function that will create a new model from the JSON specification.\n",
    "\n",
    "The weights are saved directly from the model using the save_weights() function and later loaded using the symmetrical load_weights() function.\n",
    "\n",
    "The example below trains and evaluates a simple model on the Pima Indians dataset. The model is then converted to JSON format and written to model.json in the local directory. The network weights are written to model.h5 in the local directory.\n",
    "\n",
    "The model and weight data is loaded from the saved files and a new model is created. It is important to compile the loaded model before it is used. This is so that predictions made using the model can use the appropriate efficient computation from the Keras backend.\n",
    "\n",
    "The model is evaluated in the same way printing the same evaluation score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20ad6d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 76.43%\n",
      "Saved model to disk\n",
      "Loaded model from disk\n",
      "accuracy: 76.43%\n"
     ]
    }
   ],
   "source": [
    "# # MLP for Pima Indians Dataset Serialize to JSON and HDF5\n",
    "from tensorflow.keras.models import Sequential, model_from_json\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    " \n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"pimaindianmodel.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"pimaindianmodel.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n",
    "# load json and create model\n",
    "json_file = open('pimaindianmodel.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"pimaindianmodel.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "386693ee",
   "metadata": {},
   "source": [
    "The JSON format of the model looks like the following:\n",
    "\n",
    "{  \n",
    "   \"class_name\":\"Sequential\",\n",
    "   \"config\":{  \n",
    "      \"name\":\"sequential_1\",\n",
    "      \"layers\":[  \n",
    "         {  \n",
    "            \"class_name\":\"Dense\",\n",
    "            \"config\":{  \n",
    "               \"name\":\"dense_1\",\n",
    "               \"trainable\":true,\n",
    "               \"batch_input_shape\":[  \n",
    "                  null,\n",
    "                  8\n",
    "               ],\n",
    "               \"dtype\":\"float32\",\n",
    "               \"units\":12,\n",
    "               \"activation\":\"relu\",\n",
    "               \"use_bias\":true,\n",
    "               \"kernel_initializer\":{  \n",
    "                  \"class_name\":\"VarianceScaling\",\n",
    "                  \"config\":{  \n",
    "                     \"scale\":1.0,\n",
    "                     \"mode\":\"fan_avg\",\n",
    "                     \"distribution\":\"uniform\",\n",
    "                     \"seed\":null\n",
    "                  }\n",
    "               },\n",
    "               \"bias_initializer\":{  \n",
    "                  \"class_name\":\"Zeros\",\n",
    "                  \"config\":{  \n",
    " \n",
    "                  }\n",
    "               },\n",
    "               \"kernel_regularizer\":null,\n",
    "               \"bias_regularizer\":null,\n",
    "               \"activity_regularizer\":null,\n",
    "               \"kernel_constraint\":null,\n",
    "               \"bias_constraint\":null\n",
    "            }\n",
    "         },\n",
    "         {  \n",
    "            \"class_name\":\"Dense\",\n",
    "            \"config\":{  \n",
    "               \"name\":\"dense_2\",\n",
    "               \"trainable\":true,\n",
    "               \"dtype\":\"float32\",\n",
    "               \"units\":8,\n",
    "               \"activation\":\"relu\",\n",
    "               \"use_bias\":true,\n",
    "               \"kernel_initializer\":{  \n",
    "                  \"class_name\":\"VarianceScaling\",\n",
    "                  \"config\":{  \n",
    "                     \"scale\":1.0,\n",
    "                     \"mode\":\"fan_avg\",\n",
    "                     \"distribution\":\"uniform\",\n",
    "                     \"seed\":null\n",
    "                  }\n",
    "               },\n",
    "               \"bias_initializer\":{  \n",
    "                  \"class_name\":\"Zeros\",\n",
    "                  \"config\":{  \n",
    " \n",
    "                  }\n",
    "               },\n",
    "               \"kernel_regularizer\":null,\n",
    "               \"bias_regularizer\":null,\n",
    "               \"activity_regularizer\":null,\n",
    "               \"kernel_constraint\":null,\n",
    "               \"bias_constraint\":null\n",
    "            }\n",
    "         },\n",
    "         {  \n",
    "            \"class_name\":\"Dense\",\n",
    "            \"config\":{  \n",
    "               \"name\":\"dense_3\",\n",
    "               \"trainable\":true,\n",
    "               \"dtype\":\"float32\",\n",
    "               \"units\":1,\n",
    "               \"activation\":\"sigmoid\",\n",
    "               \"use_bias\":true,\n",
    "               \"kernel_initializer\":{  \n",
    "                  \"class_name\":\"VarianceScaling\",\n",
    "                  \"config\":{  \n",
    "                     \"scale\":1.0,\n",
    "                     \"mode\":\"fan_avg\",\n",
    "                     \"distribution\":\"uniform\",\n",
    "                     \"seed\":null\n",
    "                  }\n",
    "               },\n",
    "               \"bias_initializer\":{  \n",
    "                  \"class_name\":\"Zeros\",\n",
    "                  \"config\":{  \n",
    " \n",
    "                  }\n",
    "               },\n",
    "               \"kernel_regularizer\":null,\n",
    "               \"bias_regularizer\":null,\n",
    "               \"activity_regularizer\":null,\n",
    "               \"kernel_constraint\":null,\n",
    "               \"bias_constraint\":null\n",
    "            }\n",
    "         }\n",
    "      ]\n",
    "   },\n",
    "   \"keras_version\":\"2.2.5\",\n",
    "   \"backend\":\"tensorflow\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf840ba",
   "metadata": {},
   "source": [
    "# Save Your Neural Network Model to YAML"
   ]
  },
  {
   "cell_type": "raw",
   "id": "604aeaf8",
   "metadata": {},
   "source": [
    "\n",
    "Note: This method only applies to TensorFlow 2.5 or earlier. If you run it in later versions of TensorFlow, you will see a RuntimeError with the message “Method model.to_yaml() has been removed due to security risk of arbitrary code execution. Please use model.to_json() instead.”\n",
    "\n",
    "This example is much the same as the above JSON example, except the YAML format is used for the model specification.\n",
    "\n",
    "Note, this example assumes that you have PyYAML 5 installed, for example:\n",
    "\n",
    "!pip install PyYAML\n",
    "\n",
    "In this example, the model is described using YAML, saved to file model.yaml and later loaded into a new model via the model_from_yaml() function.\n",
    "\n",
    "Weights are handled in the same way as above in HDF5 format as model.h5.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "206c2320",
   "metadata": {},
   "source": [
    "\n",
    "# MLP for Pima Indians Dataset serialize to YAML and HDF5\n",
    "from tensorflow.keras.models import Sequential, model_from_yaml\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy\n",
    "import os\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n",
    "# load pima indians dataset\n",
    "dataset = numpy.loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# Compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    " \n",
    "# serialize model to YAML\n",
    "model_yaml = model.to_yaml()\n",
    "with open(\"model.yaml\", \"w\") as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    " \n",
    "# later...\n",
    " \n",
    "# load YAML and create model\n",
    "yaml_file = open('model.yaml', 'r')\n",
    "loaded_model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "loaded_model = model_from_yaml(loaded_model_yaml)\n",
    "# load weights into new model\n",
    "loaded_model.load_weights(\"model.h5\")\n",
    "print(\"Loaded model from disk\")\n",
    " \n",
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "Running the example displays the following output.\n",
    "\n",
    "acc: 78.78%\n",
    "Saved model to disk\n",
    "Loaded model from disk\n",
    "acc: 78.78%\n",
    "The model described in YAML format looks like the following:\n",
    "\n",
    "backend: tensorflow\n",
    "class_name: Sequential\n",
    "config:\n",
    "  layers:\n",
    "  - class_name: Dense\n",
    "    config:\n",
    "      activation: relu\n",
    "      activity_regularizer: null\n",
    "      batch_input_shape: !!python/tuple\n",
    "      - null\n",
    "      - 8\n",
    "      bias_constraint: null\n",
    "      bias_initializer:\n",
    "        class_name: Zeros\n",
    "        config: {}\n",
    "      bias_regularizer: null\n",
    "      dtype: float32\n",
    "      kernel_constraint: null\n",
    "      kernel_initializer:\n",
    "        class_name: VarianceScaling\n",
    "        config:\n",
    "          distribution: uniform\n",
    "          mode: fan_avg\n",
    "          scale: 1.0\n",
    "          seed: null\n",
    "      kernel_regularizer: null\n",
    "      name: dense_1\n",
    "      trainable: true\n",
    "      units: 12\n",
    "      use_bias: true\n",
    "  - class_name: Dense\n",
    "    config:\n",
    "      activation: relu\n",
    "      activity_regularizer: null\n",
    "      bias_constraint: null\n",
    "      bias_initializer:\n",
    "        class_name: Zeros\n",
    "        config: {}\n",
    "      bias_regularizer: null\n",
    "      dtype: float32\n",
    "      kernel_constraint: null\n",
    "      kernel_initializer:\n",
    "        class_name: VarianceScaling\n",
    "        config:\n",
    "          distribution: uniform\n",
    "          mode: fan_avg\n",
    "          scale: 1.0\n",
    "          seed: null\n",
    "      kernel_regularizer: null\n",
    "      name: dense_2\n",
    "      trainable: true\n",
    "      units: 8\n",
    "      use_bias: true\n",
    "  - class_name: Dense\n",
    "    config:\n",
    "      activation: sigmoid\n",
    "      activity_regularizer: null\n",
    "      bias_constraint: null\n",
    "      bias_initializer:\n",
    "        class_name: Zeros\n",
    "        config: {}\n",
    "      bias_regularizer: null\n",
    "      dtype: float32\n",
    "      kernel_constraint: null\n",
    "      kernel_initializer:\n",
    "        class_name: VarianceScaling\n",
    "        config:\n",
    "          distribution: uniform\n",
    "          mode: fan_avg\n",
    "          scale: 1.0\n",
    "          seed: null\n",
    "      kernel_regularizer: null\n",
    "      name: dense_3\n",
    "      trainable: true\n",
    "      units: 1\n",
    "      use_bias: true\n",
    "  name: sequential_1\n",
    "keras_version: 2.2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d045b042",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "595551db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be590f42",
   "metadata": {},
   "source": [
    "# Save Model Weights and Architecture Together"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ff59e0d",
   "metadata": {},
   "source": [
    "Keras also supports a simpler interface to save both the model weights and model architecture together into a single H5 file.\n",
    "\n",
    "Saving the model in this way includes everything we need to know about the model, including:\n",
    "\n",
    "Model weights.\n",
    "Model architecture.\n",
    "Model compilation details (loss and metrics).\n",
    "Model optimizer state.\n",
    "This means that we can load and use the model directly, without having to re-compile it as we did in the examples above.\n",
    "\n",
    "Note: this is the preferred way for saving and loading your Keras model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7acba73d",
   "metadata": {},
   "source": [
    "# How to Save a Keras Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d2502ba",
   "metadata": {},
   "source": [
    "\n",
    "You can save your model by calling the save() function on the model and specifying the filename.\n",
    "\n",
    "The example below demonstrates this by first fitting a model, evaluating it and saving it to the file model.h5.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40492289",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 77.34%\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# MLP for Pima Indians Dataset saved to single file\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# load pima indians dataset\n",
    "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# compile model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(X, Y, epochs=150, batch_size=10, verbose=0)\n",
    "# evaluate the model\n",
    "scores = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))\n",
    "# save model and architecture to single file\n",
    "model.save(\"pimaindianmodel01.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8855a262",
   "metadata": {},
   "source": [
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "Running the example fits the model, summarizes the models performance on the training dataset and saves the model to file.\n",
    "\n",
    "acc: 77.30%\n",
    "Saved model to disk\n",
    "We can later load this model from file and use it.\n",
    "\n",
    "Note that in Keras library, there is another function doing the same, as follows:\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "raw",
   "id": "b8887a4e",
   "metadata": {},
   "source": [
    "\n",
    "# equivalent to: model.save(\"model.h5\")\n",
    "from tensorflow.keras.models import save_model\n",
    "save_model(model, \"pimaindianmodel01.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d793c97",
   "metadata": {},
   "source": [
    "# How to Load a Keras Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7e224f5d",
   "metadata": {},
   "source": [
    "\n",
    "Your saved model can then be loaded later by calling the load_model() function and passing the filename. The function returns the model with the same architecture and weights.\n",
    "\n",
    "In this case, we load the model, summarize the architecture and evaluate it on the same dataset to confirm the weights and architecture are the same.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8ec12d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_9 (Dense)             (None, 12)                108       \n",
      "                                                                 \n",
      " dense_10 (Dense)            (None, 8)                 104       \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 221\n",
      "Trainable params: 221\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "accuracy: 77.34%\n"
     ]
    }
   ],
   "source": [
    "# fix random seed for reproducibility\n",
    "numpy.random.seed(7)\n",
    "# load and evaluate a saved model\n",
    "from numpy import loadtxt\n",
    "from tensorflow.keras.models import load_model\n",
    " \n",
    "# load model\n",
    "model = load_model('pimaindianmodel01.h5')\n",
    "# summarize model.\n",
    "model.summary()\n",
    "# load dataset\n",
    "dataset = loadtxt(\"pima-indians-diabetes.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:,0:8]\n",
    "Y = dataset[:,8]\n",
    "# evaluate the model\n",
    "score = model.evaluate(X, Y, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (model.metrics_names[1], score[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7c69ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "How did we get the total parameters to 221?\n",
    "In the first hidden layer : (8 * 12) coefficients + 12 constants = 96 + 12 = 108\n",
    "In the second hidden layer :(12 * 8) coefficients + 8 constants  = 96 +  8 = 104\n",
    "In the final output layer : (8 * 1) coefficients + 1 constant    =  8 +  1 =   9\n",
    "Thus 108 + 104 + 9 = 221 parameters.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d302eb0",
   "metadata": {},
   "source": [
    "Running the example first loads the model, prints a summary of the model architecture then evaluates the loaded model on the same dataset.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "The model achieves the same accuracy score which in this case is 77%.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887d2ba2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d46d55dc",
   "metadata": {},
   "source": [
    "# Protocol Buffer Format"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2999bb63",
   "metadata": {},
   "source": [
    "\n",
    "While saving and loading a Keras model using HDF5 format is the recommended way, TensorFlow supports yet another format, the protocol buffer. It is considered faster to save and load a protocol buffer format but doing so will produce multiple files. The syntax is the same, except that we do not need to provide the .h5 extension to the filename:\n",
    "\n",
    "# save model and architecture to single file\n",
    "model.save(\"model\")\n",
    " \n",
    "# ... later\n",
    " \n",
    "# load model\n",
    "model = load_model('model')\n",
    "# print summary\n",
    "model.summary()\n",
    "These will create a directory “model” with the following files:\n",
    "\n",
    "model/\n",
    "|-- assets/\n",
    "|-- keras_metadata.pb\n",
    "|-- saved_model.pb\n",
    "`-- variables/\n",
    "    |-- variables.data-00000-of-00001\n",
    "    `-- variables.index\n",
    "This is also the format we used to save a model in TensorFlow v1.x. You may encounter this when you download a pretrained model from TensorFlow Hub.\n",
    "\n",
    "Further Reading\n",
    "How can I save a Keras model? in the Keras documentation.\n",
    "About Keras models in the Keras documentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a75935a",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d6cb46ac",
   "metadata": {},
   "source": [
    "In this post, you discovered how to serialize your Keras deep learning models.\n",
    "\n",
    "You learned how you can save your trained models to files and later load them up and use them to make predictions.\n",
    "\n",
    "You also learned that model weights are easily stored using  HDF5 format and that the network structure can be saved in either JSON or YAML format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
