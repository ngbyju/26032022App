{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dbd9882",
   "metadata": {},
   "source": [
    "# Applying Convolutional Neural Network on mnist dataset\n",
    "https://www.geeksforgeeks.org/applying-convolutional-neural-network-on-mnist-dataset/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d705a1e0",
   "metadata": {},
   "source": [
    "CNN is basically a model known to be Convolutional Neural Network and in recent times it has gained a lot of popularity because of its usefulness. CNN uses multilayer perceptrons to do computational works. CNN uses relatively little pre-processing compared to other image classification algorithms. This means the network learns through filters that in traditional algorithms were hand-engineered. So, for the image processing tasks CNNs are the best-suited option.\n",
    "\n",
    "MNIST dataset: \n",
    "mnist dataset is a dataset of handwritten images as shown below in the image."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d733dc8c",
   "metadata": {},
   "source": [
    "We can get 99.06% accuracy by using CNN(Convolutional Neural Network) with a functional model. The reason for using a functional model is to maintain easiness while connecting the layers.\n",
    " \n",
    "\n",
    "Firstly, include all necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99ab0f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend as k"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d7ad5317",
   "metadata": {},
   "source": [
    "Create the train data and test data\n",
    "Test data: Used for testing the model that how our model has been trained. \n",
    "Train data: Used to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1834a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f084b646",
   "metadata": {},
   "source": [
    "While proceeding further, img_rows and img_cols are used as the image dimensions. In mnist dataset, it is 28 and 28. We also need to check the data format i.e. ‘channels_first’ or ‘channels_last’. In CNN, we can normalize data before hands such that large terms of the calculations can be reduced to smaller terms. Like, we can normalize the x_train and x_test data by dividing it by 255.\n",
    "Checking data-format: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "897dfa83",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_rows, img_cols=28, 28\n",
    " \n",
    "if k.image_data_format() == 'channels_first':\n",
    "   x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
    "   x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
    "   inpx = (1, img_rows, img_cols)\n",
    " \n",
    "else:\n",
    "   x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
    "   x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
    "   inpx = (img_rows, img_cols, 1)\n",
    " \n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9479e9f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is channels_last\n"
     ]
    }
   ],
   "source": [
    "if inpx == (1, 28, 28): \n",
    "    print (\"It is channels_first\")\n",
    "    \n",
    "else:\n",
    "    print (\"It is channels_last\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e7999a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inpx"
   ]
  },
  {
   "cell_type": "raw",
   "id": "18daceee",
   "metadata": {},
   "source": [
    "Description of the output classes:\n",
    "Since the output of the model can comprise any of the digits between 0 to 9. so, we need 10 classes in output. To make output for 10 classes, use keras.utils.to_categorical function, which will provide the 10 columns. Out of these 10 columns, only one value will be one and the rest 9 will be zero and this one value of the output will denote the class of the digit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8fabf4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f67dae08",
   "metadata": {},
   "source": [
    "Now, the dataset is ready so let’s move towards the CNN model :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0caa1d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpx = Input(shape=inpx)\n",
    "layer1 = Conv2D(32, kernel_size=(3, 3), activation='relu')(inpx)\n",
    "layer2 = Conv2D(64, (3, 3), activation='relu')(layer1)\n",
    "layer3 = MaxPooling2D(pool_size=(3, 3))(layer2)\n",
    "layer4 = Dropout(0.5)(layer3)\n",
    "layer5 = Flatten()(layer4)\n",
    "layer6 = Dense(250, activation='sigmoid')(layer5)\n",
    "layer7 = Dense(10, activation='softmax')(layer6)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bf9a7a0",
   "metadata": {},
   "source": [
    "Explanation of the working of each layer in the CNN model:\n",
    "layer1 is the Conv2d layer which convolves the image using 32 filters each of size (3*3). \n",
    "layer2 is again a Conv2D layer which is also used to convolve the image and is using 64 filters each of size (3*3). \n",
    "layer3 is the MaxPooling2D layer which picks the max value out of a matrix of size (3*3). \n",
    "layer4 is showing Dropout at a rate of 0.5. \n",
    "layer5 is flattening the output obtained from layer4 and this flattens output is passed to layer6. \n",
    "layer6 is a hidden layer of a neural network containing 250 neurons. \n",
    "layer7 is the output layer having 10 neurons for 10 classes of output that is using the softmax function.\n",
    "\n",
    "Calling compile and fit function: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84d460b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "120/120 [==============================] - 37s 301ms/step - loss: 2.5699 - accuracy: 0.0993\n",
      "Epoch 2/12\n",
      "120/120 [==============================] - 47s 393ms/step - loss: 2.5407 - accuracy: 0.0993\n",
      "Epoch 3/12\n",
      "120/120 [==============================] - 54s 447ms/step - loss: 2.5122 - accuracy: 0.0993\n",
      "Epoch 4/12\n",
      "120/120 [==============================] - 40s 336ms/step - loss: 2.4852 - accuracy: 0.0993\n",
      "Epoch 5/12\n",
      "120/120 [==============================] - 36s 296ms/step - loss: 2.4589 - accuracy: 0.0993\n",
      "Epoch 6/12\n",
      "120/120 [==============================] - 34s 285ms/step - loss: 2.4344 - accuracy: 0.0993\n",
      "Epoch 7/12\n",
      "120/120 [==============================] - 34s 282ms/step - loss: 2.4112 - accuracy: 0.0993\n",
      "Epoch 8/12\n",
      "120/120 [==============================] - 34s 284ms/step - loss: 2.3888 - accuracy: 0.0993\n",
      "Epoch 9/12\n",
      "120/120 [==============================] - 34s 280ms/step - loss: 2.3686 - accuracy: 0.0993\n",
      "Epoch 10/12\n",
      "120/120 [==============================] - 34s 284ms/step - loss: 2.3496 - accuracy: 0.0993\n",
      "Epoch 11/12\n",
      "120/120 [==============================] - 33s 279ms/step - loss: 2.3320 - accuracy: 0.0993\n",
      "Epoch 12/12\n",
      "120/120 [==============================] - 33s 279ms/step - loss: 2.3162 - accuracy: 0.0993\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2a0b4a307c0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Model([inpx], layer7)\n",
    "model.compile(optimizer=\"Adadelta\",loss=\"categorical_crossentropy\", metrics=['accuracy'])\n",
    " \n",
    "model.fit(x_train, y_train, epochs=12, batch_size=500)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "72cd10b3",
   "metadata": {},
   "source": [
    "Firstly, we made an object of the model as shown in the above-given lines, where [inpx] is the input in the model and layer7 is the output of the model. We compiled the model using the required optimizer, loss function and printed the accuracy and at the last model.fit was called along with parameters like x_train(means image vectors), y_train(means the label), number of epochs, and the batch size. Using fit function x_train, y_train dataset is fed to model in particular batch size.\n",
    "\n",
    "Evaluate function: \n",
    "model.evaluate provides the score for the test data i.e. provided the test data to the model. Now, the model will predict the class of the data, and the predicted class will be matched with the y_test label to give us the accuracy. \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58620d3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss= 2.303474187850952\n",
      "accuracy= 0.10320000350475311\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print('loss=', score[0])\n",
    "print('accuracy=', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be8e480",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
