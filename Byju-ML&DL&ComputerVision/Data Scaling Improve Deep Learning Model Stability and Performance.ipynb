{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a129863d",
   "metadata": {},
   "source": [
    "# How to use Data Scaling Improve Deep Learning Model Stability and Performance\n",
    "https://machinelearningmastery.com/how-to-improve-neural-network-stability-and-modeling-performance-with-data-scaling/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "138ca390",
   "metadata": {},
   "source": [
    "Deep learning neural networks learn how to map inputs to outputs from examples in a training dataset.\n",
    "\n",
    "The weights of the model are initialized to small random values and updated via an optimization algorithm in response to estimates of error on the training dataset.\n",
    "\n",
    "Given the use of small weights in the model and the use of error between predictions and expected values, the scale of inputs and outputs used to train the model are an important factor. Unscaled input variables can result in a slow or unstable learning process, whereas unscaled target variables on regression problems can result in exploding gradients causing the learning process to fail.\n",
    "\n",
    "Data preparation involves using techniques such as the normalization and standardization to rescale input and output variables prior to training a neural network model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "a7ee5f82",
   "metadata": {},
   "source": [
    "After completing this tutorial, you will know:\n",
    "\n",
    "Data scaling is a recommended pre-processing step when working with deep learning neural networks.\n",
    "Data scaling can be achieved by normalizing or standardizing real-valued input and output variables.\n",
    "How to apply standardization and normalization to improve the performance of a Multilayer Perceptron model on a regression predictive modeling problem."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cd24dc06",
   "metadata": {},
   "source": [
    "Tutorial Overview\n",
    "This tutorial is divided into six parts; they are:\n",
    "\n",
    "The Scale of Your Data Matters\n",
    "Data Scaling Methods\n",
    "Regression Predictive Modeling Problem\n",
    "Multilayer Perceptron With Unscaled Data\n",
    "Multilayer Perceptron With Scaled Output Variables\n",
    "Multilayer Perceptron With Scaled Input Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eea24bc",
   "metadata": {},
   "source": [
    "# The Scale of Your Data Matters"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e7107bd3",
   "metadata": {},
   "source": [
    "\n",
    "Deep learning neural network models learn a mapping from input variables to an output variable.\n",
    "\n",
    "As such, the scale and distribution of the data drawn from the domain may be different for each variable.\n",
    "\n",
    "Input variables may have different units (e.g. feet, kilometers, and hours) that, in turn, may mean the variables have different scales.\n",
    "\n",
    "Differences in the scales across input variables may increase the difficulty of the problem being modeled. An example of this is that large input values (e.g. a spread of hundreds or thousands of units) can result in a model that learns large weight values. A model with large weight values is often unstable, meaning that it may suffer from poor performance during learning and sensitivity to input values resulting in higher generalization error.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "One of the most common forms of pre-processing consists of a simple linear rescaling of the input variables.\n",
    "\n",
    "— Page 298, Neural Networks for Pattern Recognition, 1995.\n",
    "\n",
    "A target variable with a large spread of values, in turn, may result in large error gradient values causing weight values to change dramatically, making the learning process unstable.\n",
    "\n",
    "Scaling input and output variables is a critical step in using neural network models.\n",
    "\n",
    "In practice it is nearly always advantageous to apply pre-processing transformations to the input data before it is presented to a network. Similarly, the outputs of the network are often post-processed to give the required output values.\n",
    "\n",
    "— Page 296, Neural Networks for Pattern Recognition, 1995."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6465677",
   "metadata": {},
   "source": [
    "# Scaling Input Variables"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0627a3a2",
   "metadata": {},
   "source": [
    "\n",
    "The input variables are those that the network takes on the input or visible layer in order to make a prediction.\n",
    "\n",
    "A good rule of thumb is that input variables should be small values, probably in the range of 0-1 or standardized with a zero mean and a standard deviation of one.\n",
    "\n",
    "Whether input variables require scaling depends on the specifics of your problem and of each variable.\n",
    "\n",
    "You may have a sequence of quantities as inputs, such as prices or temperatures.\n",
    "\n",
    "If the distribution of the quantity is normal, then it should be standardized, otherwise the data should be normalized. This applies if the range of quantity values is large (10s, 100s, etc.) or small (0.01, 0.0001).\n",
    "\n",
    "If the quantity values are small (near 0-1) and the distribution is limited (e.g. standard deviation near 1) then perhaps you can get away with no scaling of the data.\n",
    "\n",
    "Problems can be complex and it may not be clear how to best scale input data.\n",
    "\n",
    "If in doubt, normalize the input sequence. If you have the resources, explore modeling with the raw data, standardized data, and normalized data and see if there is a beneficial difference in the performance of the resulting model.\n",
    "\n",
    "If the input variables are combined linearly, as in an MLP [Multilayer Perceptron], then it is rarely strictly necessary to standardize the inputs, at least in theory. […] However, there are a variety of practical reasons why standardizing the inputs can make training faster and reduce the chances of getting stuck in local optima."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1da13e",
   "metadata": {},
   "source": [
    "# Scaling Output Variables"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2d3ed215",
   "metadata": {},
   "source": [
    "The output variable is the variable predicted by the network.\n",
    "\n",
    "You must ensure that the scale of your output variable matches the scale of the activation function (transfer function) on the output layer of your network.\n",
    "\n",
    "If your output activation function has a range of [0,1], then obviously you must ensure that the target values lie within that range. But it is generally better to choose an output activation function suited to the distribution of the targets than to force your data to conform to the output activation function.\n",
    "\n",
    "— Should I normalize/standardize/rescale the data? Neural Nets FAQ\n",
    "\n",
    "If your problem is a regression problem, then the output will be a real value.\n",
    "\n",
    "This is best modeled with a linear activation function. If the distribution of the value is normal, then you can standardize the output variable. Otherwise, the output variable can be normalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f308943f",
   "metadata": {},
   "source": [
    "# Data Scaling Methods"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3d6855d7",
   "metadata": {},
   "source": [
    "\n",
    "There are two types of scaling of your data that you may want to consider: normalization and standardization.\n",
    "\n",
    "These can both be achieved using the scikit-learn library.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea27bc53",
   "metadata": {},
   "source": [
    "# Data Normalization"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c226ed89",
   "metadata": {},
   "source": [
    "\n",
    "Normalization is a rescaling of the data from the original range so that all values are within the range of 0 and 1.\n",
    "\n",
    "Normalization requires that you know or are able to accurately estimate the minimum and maximum observable values. You may be able to estimate these values from your available data.\n",
    "\n",
    "A value is normalized as follows:\n",
    "\n",
    "y = (x - min) / (max - min)\n",
    "Where the minimum and maximum values pertain to the value x being normalized.\n",
    "\n",
    "For example, for a dataset, we could guesstimate the min and max observable values as 30 and -10. We can then normalize any value, like 18.8, as follows:\n",
    "\n",
    "y = (x - min) / (max - min)\n",
    "y = (18.8 - (-10)) / (30 - (-10))\n",
    "y = 28.8 / 40\n",
    "y = 0.72\n",
    "You can see that if an x value is provided that is outside the bounds of the minimum and maximum values, the resulting value will not be in the range of 0 and 1. You could check for these observations prior to making predictions and either remove them from the dataset or limit them to the pre-defined maximum or minimum values.\n",
    "\n",
    "You can normalize your dataset using the scikit-learn object MinMaxScaler.\n",
    "\n",
    "Good practice usage with the MinMaxScaler and other scaling techniques is as follows:\n",
    "\n",
    "Fit the scaler using available training data. For normalization, this means the training data will be used to estimate the minimum and maximum observable values. This is done by calling the fit() function.\n",
    "Apply the scale to training data. This means you can use the normalized data to train your model. This is done by calling the transform() function.\n",
    "Apply the scale to data going forward. This means you can prepare new data in the future on which you want to make predictions.\n",
    "The default scale for the MinMaxScaler is to rescale variables into the range [0,1], although a preferred scale can be specified via the “feature_range” argument and specify a tuple including the min and the max for all variables.\n",
    "\n",
    "# create scaler\n",
    "scaler = MinMaxScaler(feature_range=(-1,1))\n",
    "If needed, the transform can be inverted. This is useful for converting predictions back into their original scale for reporting or plotting. This can be done by calling the inverse_transform() function.\n",
    "\n",
    "The example below provides a general demonstration for using the MinMaxScaler to normalize data.\n",
    "\n",
    "# demonstrate data normalization with sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load data\n",
    "data = ...\n",
    "# create scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit scaler on data\n",
    "scaler.fit(data)\n",
    "# apply transform\n",
    "normalized = scaler.transform(data)\n",
    "# inverse transform\n",
    "inverse = scaler.inverse_transform(normalized)\n",
    "You can also perform the fit and transform in a single step using the fit_transform() function; for example:\n",
    "\n",
    "# demonstrate data normalization with sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# load data\n",
    "data = ...\n",
    "# create scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit and transform in one step\n",
    "normalized = scaler.fit_transform(data)\n",
    "# inverse transform\n",
    "inverse = scaler.inverse_transform(normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69f6eb0",
   "metadata": {},
   "source": [
    "# Data Standardization"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3dbf5b3",
   "metadata": {},
   "source": [
    "\n",
    "Standardizing a dataset involves rescaling the distribution of values so that the mean of observed values is 0 and the standard deviation is 1. It is sometimes referred to as “whitening.”\n",
    "\n",
    "This can be thought of as subtracting the mean value or centering the data.\n",
    "\n",
    "Like normalization, standardization can be useful, and even required in some machine learning algorithms when your data has input values with differing scales.\n",
    "\n",
    "Standardization assumes that your observations fit a Gaussian distribution (bell curve) with a well behaved mean and standard deviation. You can still standardize your data if this expectation is not met, but you may not get reliable results.\n",
    "\n",
    "Standardization requires that you know or are able to accurately estimate the mean and standard deviation of observable values. You may be able to estimate these values from your training data.\n",
    "\n",
    "A value is standardized as follows:\n",
    "\n",
    "y = (x - mean) / standard_deviation\n",
    "Where the mean is calculated as:\n",
    "\n",
    "mean = sum(x) / count(x)\n",
    "And the standard_deviation is calculated as:\n",
    "\n",
    "standard_deviation = sqrt( sum( (x - mean)^2 ) / count(x))\n",
    "We can guesstimate a mean of 10 and a standard deviation of about 5. Using these values, we can standardize the first value of 20.7 as follows:\n",
    "\n",
    "y = (x - mean) / standard_deviation\n",
    "y = (20.7 - 10) / 5\n",
    "y = (10.7) / 5\n",
    "y = 2.14\n",
    "The mean and standard deviation estimates of a dataset can be more robust to new data than the minimum and maximum.\n",
    "\n",
    "You can standardize your dataset using the scikit-learn object StandardScaler.\n",
    "\n",
    "# demonstrate data standardization with sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# load data\n",
    "data = ...\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on data\n",
    "scaler.fit(data)\n",
    "# apply transform\n",
    "standardized = scaler.transform(data)\n",
    "# inverse transform\n",
    "inverse = scaler.inverse_transform(standardized)\n",
    "You can also perform the fit and transform in a single step using the fit_transform() function; for example:\n",
    "\n",
    "# demonstrate data standardization with sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# load data\n",
    "data = ...\n",
    "# create scaler\n",
    "scaler = StandardScaler()\n",
    "# fit and transform in one step\n",
    "standardized = scaler.fit_transform(data)\n",
    "# inverse transform\n",
    "inverse = scaler.inverse_transform(standardized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe50dc23",
   "metadata": {},
   "source": [
    "# Regression Predictive Modeling Problem"
   ]
  },
  {
   "cell_type": "raw",
   "id": "106ac92b",
   "metadata": {},
   "source": [
    "\n",
    "A regression predictive modeling problem involves predicting a real-valued quantity.\n",
    "\n",
    "We can use a standard regression problem generator provided by the scikit-learn library in the make_regression() function. This function will generate examples from a simple regression problem with a given number of input variables, statistical noise, and other properties.\n",
    "\n",
    "We will use this function to define a problem that has 20 input features; 10 of the features will be meaningful and 10 will not be relevant. A total of 1,000 examples will be randomly generated. The pseudorandom number generator will be fixed to ensure that we get the same 1,000 examples each time the code is run.\n",
    "\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "Each input variable has a Gaussian distribution, as does the target variable.\n",
    "\n",
    "We can demonstrate this by creating histograms of some of the input variables and the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9b720b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# regression predictive modeling problem\n",
    "from sklearn.datasets import make_regression\n",
    "from matplotlib import pyplot\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "# histograms of input variables\n",
    "pyplot.subplot(211)\n",
    "pyplot.hist(X[:, 0])\n",
    "pyplot.subplot(212)\n",
    "pyplot.hist(X[:, 1])\n",
    "pyplot.show()\n",
    "# histogram of target variable\n",
    "pyplot.hist(y)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0ba5dbc9",
   "metadata": {},
   "source": [
    "Running the example creates two figures.\n",
    "\n",
    "The first shows histograms of the first two of the twenty input variables, showing that each has a Gaussian data distribution."
   ]
  },
  {
   "cell_type": "raw",
   "id": "d486f2f2",
   "metadata": {},
   "source": [
    "The second figure shows a histogram of the target variable, showing a much larger range for the variable as compared to the input variables and, again, a Gaussian data distribution."
   ]
  },
  {
   "cell_type": "raw",
   "id": "4e930ddb",
   "metadata": {},
   "source": [
    "Now that we have a regression problem that we can use as the basis for the investigation, we can develop a model to address it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c76538a",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron With Unscaled Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c62fbda",
   "metadata": {},
   "source": [
    "\n",
    "We can develop a Multilayer Perceptron (MLP) model for the regression problem.\n",
    "\n",
    "A model will be demonstrated on the raw data, without any scaling of the input or output variables. We expect that model performance will be generally poor.\n",
    "\n",
    "The first step is to split the data into train and test sets so that we can fit and evaluate a model. We will generate 1,000 examples from the domain and split the dataset in half, using 500 examples for the train and test datasets.\n",
    "\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "Next, we can define an MLP model. The model will expect 20 inputs in the 20 input variables in the problem.\n",
    "\n",
    "A single hidden layer will be used with 25 nodes and a rectified linear activation function. The output layer has one node for the single target variable and a linear activation function to predict real values directly.\n",
    "\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "The mean squared error loss function will be used to optimize the model and the stochastic gradient descent optimization algorithm will be used with the sensible default configuration of a learning rate of 0.01 and a momentum of 0.9.\n",
    "\n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "The model will be fit for 100 training epochs and the test set will be used as a validation set, evaluated at the end of each training epoch.\n",
    "\n",
    "The mean squared error is calculated on the train and test datasets at the end of training to get an idea of how well the model learned the problem.\n",
    "\n",
    "# evaluate the model\n",
    "train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "test_mse = model.evaluate(testX, testy, verbose=0)\n",
    "Finally, learning curves of mean squared error on the train and test sets at the end of each training epoch are graphed using line plots, providing learning curves to get an idea of the dynamics of the model while learning the problem.\n",
    "\n",
    "# plot loss during training\n",
    "pyplot.title('Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    "Tying these elements together, the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e2a513d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: nan, Test: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# mlp with unscaled data for the regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "# evaluate the model\n",
    "train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "test_mse = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "pyplot.title('Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7800e060",
   "metadata": {},
   "source": [
    "Running the example fits the model and calculates the mean squared error on the train and test sets.\n",
    "\n",
    "In this case, the model is unable to learn the problem, resulting in predictions of NaN values. The model weights exploded during training given the very large errors and, in turn, error gradients calculated for weight updates.\n",
    "\n",
    "Train: nan, Test: nan\n",
    "This demonstrates that, at the very least, some data scaling is required for the target variable.\n",
    "\n",
    "As seen above, a line plot of training history is created but does not show anything as the model almost immediately results in a NaN mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f7b797d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.583727</td>\n",
       "      <td>0.785936</td>\n",
       "      <td>-0.171872</td>\n",
       "      <td>0.669287</td>\n",
       "      <td>1.671810</td>\n",
       "      <td>0.598318</td>\n",
       "      <td>1.498076</td>\n",
       "      <td>0.279251</td>\n",
       "      <td>-0.317058</td>\n",
       "      <td>-0.419613</td>\n",
       "      <td>-0.217961</td>\n",
       "      <td>0.811867</td>\n",
       "      <td>-0.792153</td>\n",
       "      <td>0.566210</td>\n",
       "      <td>0.974736</td>\n",
       "      <td>-0.822374</td>\n",
       "      <td>1.030072</td>\n",
       "      <td>-0.679455</td>\n",
       "      <td>-0.215406</td>\n",
       "      <td>1.031189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.836535</td>\n",
       "      <td>-0.439753</td>\n",
       "      <td>1.210371</td>\n",
       "      <td>1.495413</td>\n",
       "      <td>1.166660</td>\n",
       "      <td>-0.695817</td>\n",
       "      <td>-1.013652</td>\n",
       "      <td>-0.783010</td>\n",
       "      <td>0.740936</td>\n",
       "      <td>0.848620</td>\n",
       "      <td>1.293971</td>\n",
       "      <td>1.377905</td>\n",
       "      <td>1.141645</td>\n",
       "      <td>0.984230</td>\n",
       "      <td>-0.084615</td>\n",
       "      <td>-1.258028</td>\n",
       "      <td>1.138478</td>\n",
       "      <td>-0.619851</td>\n",
       "      <td>0.034862</td>\n",
       "      <td>0.252769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.116182</td>\n",
       "      <td>0.338823</td>\n",
       "      <td>-1.832381</td>\n",
       "      <td>0.849131</td>\n",
       "      <td>-1.001240</td>\n",
       "      <td>-0.207779</td>\n",
       "      <td>-1.016756</td>\n",
       "      <td>-0.095361</td>\n",
       "      <td>-0.735512</td>\n",
       "      <td>0.684862</td>\n",
       "      <td>-0.641591</td>\n",
       "      <td>-0.472694</td>\n",
       "      <td>-0.565611</td>\n",
       "      <td>0.533560</td>\n",
       "      <td>-1.063517</td>\n",
       "      <td>-0.367900</td>\n",
       "      <td>-1.398943</td>\n",
       "      <td>0.405313</td>\n",
       "      <td>-0.171244</td>\n",
       "      <td>0.633441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.108010</td>\n",
       "      <td>-0.404769</td>\n",
       "      <td>-0.107993</td>\n",
       "      <td>-1.146575</td>\n",
       "      <td>-0.692175</td>\n",
       "      <td>0.567931</td>\n",
       "      <td>0.423871</td>\n",
       "      <td>-0.762185</td>\n",
       "      <td>-1.216825</td>\n",
       "      <td>-0.168903</td>\n",
       "      <td>0.103165</td>\n",
       "      <td>-1.376652</td>\n",
       "      <td>-0.839116</td>\n",
       "      <td>0.739115</td>\n",
       "      <td>-0.584282</td>\n",
       "      <td>0.287434</td>\n",
       "      <td>1.451720</td>\n",
       "      <td>0.464322</td>\n",
       "      <td>1.279857</td>\n",
       "      <td>1.070726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.933846</td>\n",
       "      <td>0.785996</td>\n",
       "      <td>0.237308</td>\n",
       "      <td>-0.245901</td>\n",
       "      <td>0.878658</td>\n",
       "      <td>-2.166559</td>\n",
       "      <td>0.287565</td>\n",
       "      <td>1.147085</td>\n",
       "      <td>1.037847</td>\n",
       "      <td>0.104104</td>\n",
       "      <td>-1.117821</td>\n",
       "      <td>-0.915913</td>\n",
       "      <td>-0.988966</td>\n",
       "      <td>-0.552877</td>\n",
       "      <td>1.325872</td>\n",
       "      <td>2.537089</td>\n",
       "      <td>1.114503</td>\n",
       "      <td>-0.001376</td>\n",
       "      <td>-1.677632</td>\n",
       "      <td>-0.470153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.583727  0.785936 -0.171872  0.669287  1.671810  0.598318  1.498076   \n",
       "1  1.836535 -0.439753  1.210371  1.495413  1.166660 -0.695817 -1.013652   \n",
       "2 -0.116182  0.338823 -1.832381  0.849131 -1.001240 -0.207779 -1.016756   \n",
       "3 -0.108010 -0.404769 -0.107993 -1.146575 -0.692175  0.567931  0.423871   \n",
       "4 -1.933846  0.785996  0.237308 -0.245901  0.878658 -2.166559  0.287565   \n",
       "\n",
       "         7         8         9         10        11        12        13  \\\n",
       "0  0.279251 -0.317058 -0.419613 -0.217961  0.811867 -0.792153  0.566210   \n",
       "1 -0.783010  0.740936  0.848620  1.293971  1.377905  1.141645  0.984230   \n",
       "2 -0.095361 -0.735512  0.684862 -0.641591 -0.472694 -0.565611  0.533560   \n",
       "3 -0.762185 -1.216825 -0.168903  0.103165 -1.376652 -0.839116  0.739115   \n",
       "4  1.147085  1.037847  0.104104 -1.117821 -0.915913 -0.988966 -0.552877   \n",
       "\n",
       "         14        15        16        17        18        19  \n",
       "0  0.974736 -0.822374  1.030072 -0.679455 -0.215406  1.031189  \n",
       "1 -0.084615 -1.258028  1.138478 -0.619851  0.034862  0.252769  \n",
       "2 -1.063517 -0.367900 -1.398943  0.405313 -0.171244  0.633441  \n",
       "3 -0.584282  0.287434  1.451720  0.464322  1.279857  1.070726  \n",
       "4  1.325872  2.537089  1.114503 -0.001376 -1.677632 -0.470153  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame(trainX).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0b7647",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron With Scaled Output Variables"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fce7b3a7",
   "metadata": {},
   "source": [
    "\n",
    "The MLP model can be updated to scale the target variable.\n",
    "\n",
    "Reducing the scale of the target variable will, in turn, reduce the size of the gradient used to update the weights and result in a more stable model and training process.\n",
    "\n",
    "Given the Gaussian distribution of the target variable, a natural method for rescaling the variable would be to standardize the variable. This requires estimating the mean and standard deviation of the variable and using these estimates to perform the rescaling.\n",
    "\n",
    "It is best practice is to estimate the mean and standard deviation of the training dataset and use these variables to scale the train and test dataset. This is to avoid any data leakage during the model evaluation process.\n",
    "\n",
    "The scikit-learn transformers expect input data to be matrices of rows and columns, therefore the 1D arrays for the target variable will have to be reshaped into 2D arrays prior to the transforms.\n",
    "\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "We can then create and apply the StandardScaler to rescale the target variable.\n",
    "\n",
    "# created scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bd886f9",
   "metadata": {},
   "source": [
    "Rescaling the target variable means that estimating the performance of the model and plotting the learning curves will calculate an MSE in squared units of the scaled variable rather than squared units of the original scale. This can make interpreting the error within the context of the domain challenging.\n",
    "\n",
    "In practice, it may be helpful to estimate the performance of the model by first inverting the transform on the test dataset target variable and on the model predictions and estimating model performance using the root mean squared error on the unscaled data. This is left as an exercise to the reader.\n",
    "\n",
    "The complete example of standardizing the target variable for the MLP on the regression problem is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "30b38b6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.004, Test: 0.011\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAApw0lEQVR4nO3deZwcdZ3/8denqo+5cjGZhByEBIlIRA6NCMKukUMIqMGf+2OBxVtZdz1/v9UFdlcU3XVZXX24/hbIsmy8EHi4ggtKWFCBBQWEgIiBcITLDAPJJOSau7vr8/ujqmc6k5nMJJmZpnrez8ejH+muqq7+VPfkXd/61mXujoiIpF9Q7QJERGRsKNBFRGqEAl1EpEYo0EVEaoQCXUSkRijQRURqhAJdJOXM7Etmdk2165DqU6DXODN73sxOqeLnP2Vmrx1i+F1m5mZ21KDh/5UMXzZRNVZ89kfM7Akz22lmG83sFjObMtF1jCUzW2ZmkZl1DHocX+3aZOwp0GXcmNlrgMDdnxpmkqeA91dM3wwcB7RPQHm7MLO3AV8FznX3KcDhwI+qUEdmHGbb5u5Ngx73DfHZZmbBoGF7Vc841S+jpECfpMwsb2bfMrO25PEtM8sn42aa2c/MbJuZvWJm95T/o5vZhWb2YtKKfdLMTt7Dx5wJrN7D+B8Cf2pmYfL6XOAnQF9FnYGZXWRmz5jZFjP7kZkdUDH+P83sZTPbbmZ3m9nrK8Z918wuT1raO83sN8lKZihvBu5z998CuPsr7v49d9+ZzKvZzG42sx1m9oCZfcXMfpWMW5hsVfSHWbIF8tHk+WvM7I6k/s1m9kMzm14x7fPJ9/oo0GlmGTM7zszuTX6D31VusZjZIjP7n2SZfg7M3MN3vEdJnf9gZr8GuoBDkmX5hJk9DTydTPcxM1uf/D3cbGZzK+ax2/RSHQr0yetviVvDRwNHAccCf5eM+yugFWgBZgN/A7iZHQZ8Enhz0oo9DXh+D59xBnDLHsa3AY8D70hevx/4/qBpPg2cBbwNmAtsBS6vGH8rsBiYBTxMvJKodC5wKTADWA/8wzC1/AY4zcwuNbMTyiu3CpcDPcAc4MPJY7QM+Mek/sOBg4AvDVHnmcB04u/8FuDvgQOAzwE3mFlLMu21wEPEQf4V4AN7UctQ3gdcAEwBXkiGnQW8BVhiZicl9Z9NvPwvANcPmkf/9PtZi+wPd9ejhh/EgXvKEMOfAc6oeH0a8Hzy/MvATcChg95zKLAJOAXIjvC5DcAWoG6Y8XcBHwXOB64DDgOeSsa1AsuS5+uAkyveNwcoAJkh5jkdcGBa8vq7wNUV488AnthDzcuBnwLbgA7gm0CYPArA6yqm/Srwq+T5wuRzM4OXb5jPOQv47aDf6MMVry8EfjDoPbcRB/cCoAg0Voy7FrhmmM9aBkTJMlU+Givq/PKg9zhwUsXr/wC+VvG6Kfk+Fg41vR7Ve6iFPnnNZaA1RvK8vBn9deLW7O1m9qyZXQTg7uuBzxK3LjeZ2fWVm96DnAzc6+49I9RxI3AS8CngB0OMPxj4SdL1sI044EvAbDMLzeyypDtmBwNbC5VdEC9XPO8iDqMhufut7v4u4lbxCuCDxCudFiADbKiY/IXdZjAMM5uVfFcvJnVew+7dJJXzPhj43+VlTpb7ROKV2Vxgq7t37kUtbe4+fdCj8v0bhnhP5bBd/lbcvYN4ZT1vhHnIBFOgT15txMFRtiAZhrvvdPe/cvdDgHcB/7fcV+7u17r7icl7HfinYeY/UncLyfy6iLtN/oKhA30DsHxQGNW5+4vAecTBewowjbilDHEXxz5z98jdfwncARxBvJO2SNxVUrag4nk5HBsqhh1Y8fwfib+rI919KvFWyeAaKy97uoG4hV65zI3ufhnwEjDDzBqHqWVfDHXJ1cphu/ytJJ/dDLw4wjxkginQJ4esmdVVPDLE3Rx/Z2YtZjYTuIS45YiZvdPMDjUzA3YQt4hLZnaYmZ2U9C/3AN3JuKEsZ887RCv9DfA2d39+iHErgX8ws4OT2lrMbEUybgrQS9xabCDuBtknZrbCzM4xsxkWO5a43/5+dy8Rb0l8ycwazGwJFf3W7t5OHG7nJ1sNHwYqd75OIe7C2WZm84DPj1DONcC7zOy0ZH51Fh9+ON/dXwDWAJeaWc7MTiRe6Y6na4EPmdnRyW//VeA3w/xeUkUK9MlhNXH4lh9fIt7htgZ4FPg98Q7Fv0+mXwz8gjiE7gOucPe7gDxwGbCZuCtjFnEY78LMjgA63P0PoynO3dvc/VfDjP4X4Gbi7p+dwP3EO98g3oH6AnGYPp6M21dbgY8RH6VR7hb5uruXd7J+kri75mXivvnvDHr/x4iDegvweuDeinGXAm8EthNvtdy4p0LcfQPxlsffEG8dbEjmXf7/eh7xd/AK8EV235E82Fzb/Tj0947wnsp6fgl8AbiBeAvhNcA5o32/TBxz15aSjC0z+2tgprv/dbVrGS9m9kHinZ4nVrsWkTKdBCDj4Xnio0VEZAIp0GXMufuEn2EpIupyERGpGdopKiJSI6rW5TJz5kxfuHBhtT5eRCSVHnrooc3u3jLUuKoF+sKFC1mzZk21Pl5EJJXMbNgzg9XlIiJSIxToIiI1QoEuIlIjdBy6iKRKoVCgtbWVnp6RLuSZbnV1dcyfP59sNjvq9yjQRSRVWltbmTJlCgsXLiS+flztcXe2bNlCa2srixYtGvX71OUiIqnS09NDc3NzzYY5gJnR3Ny811shCnQRSZ1aDvOyfVnG1AX6ky/v5Bu3P8mWjt5qlyIi8qqSukB/pr2D/3fHejZ39I08sYjIGNu2bRtXXHHFXr/vjDPOYNu2bWNfUIXUBXomiDdDCqWoypWIyGQ0XKCXSsPdvCu2evVqpk+fPk5VxVJ3lEs2jNdBCnQRqYaLLrqIZ555hqOPPppsNktTUxNz5szhkUce4fHHH+ess85iw4YN9PT08JnPfIYLLrgAGLjcSUdHB8uXL+fEE0/k3nvvZd68edx0003U19fvd20pDnRd9ldksrv0p4/xeNuOMZ3nkrlT+eK7Xj/s+Msuu4y1a9fyyCOPcNddd3HmmWeydu3a/sMLV61axQEHHEB3dzdvfvObee9730tzc/Mu83j66ae57rrr+Pd//3fOPvtsbrjhBs4///z9rj11gZ4J4y6XolroIvIqcOyxx+5yrPi3v/1tfvKTnwCwYcMGnn766d0CfdGiRRx99NEAvOlNb+L5558fk1pSF+j9LfRILXSRyW5PLemJ0tjY2P/8rrvu4he/+AX33XcfDQ0NLFu2bMhjyfP5fP/zMAzp7u4ek1pSt1M0m7TQC0W10EVk4k2ZMoWdO3cOOW779u3MmDGDhoYGnnjiCe6///4JrW3EFrqZrQLeCWxy9yOGGP9nwIXJyw7gL9z9d2NaZYVyC70YKdBFZOI1NzdzwgkncMQRR1BfX8/s2bP7x51++umsXLmSI488ksMOO4zjjjtuQmsbTZfLd4F/Bb4/zPjngLe5+1YzWw5cBbxlbMrbXbmF3qedoiJSJddee+2Qw/P5PLfeeuuQ48r95DNnzmTt2rX9wz/3uc+NWV0jBrq7321mC/cw/t6Kl/cD88egrmFlgqSFrp2iIiK7GOs+9I8AQ6+eADO7wMzWmNma9vb2ffqAbEbHoYuIDGXMAt3M3k4c6BcON427X+XuS919aUvLkPc4HVG2/0xRdbmIiFQak8MWzexI4GpgubtvGYt5Dqd/p6ha6CIiu9jvFrqZLQBuBN7n7k/tf0l7Vj6xSC10EZFdjeawxeuAZcBMM2sFvghkAdx9JXAJ0AxckVy/t+juS8er4IETi9RCFxGpNGIL3d3Pdfc57p519/nu/h/uvjIJc9z9o+4+w92PTh7jFuZQEehFtdBFZOLt6+VzAb71rW/R1dU1xhUNSN2ZomFgmOnEIhGpjldzoKfuWi4Qt9L7tFNURKqg8vK5p556KrNmzeJHP/oRvb29vOc97+HSSy+ls7OTs88+m9bWVkqlEl/4whfYuHEjbW1tvP3tb2fmzJnceeedY15bOgM9MIraKSoit14EL/9+bOd54Btg+WXDjq68fO7tt9/Oj3/8Yx544AHcnXe/+93cfffdtLe3M3fuXG655RYgvsbLtGnT+OY3v8mdd97JzJkzx7bmROq6XCA+uUiHLYpItd1+++3cfvvtHHPMMbzxjW/kiSee4Omnn+YNb3gDv/jFL7jwwgu55557mDZt2oTUk8oWeiYIdC0XEdljS3oiuDsXX3wxf/7nf77buIceeojVq1dz8cUX8453vINLLrlk3OtJZws9NLXQRaQqKi+fe9ppp7Fq1So6OjoAePHFF9m0aRNtbW00NDRw/vnn87nPfY6HH354t/eOh1S20LNhoGu5iEhVVF4+d/ny5Zx33nkcf/zxADQ1NXHNNdewfv16Pv/5zxMEAdlsliuvvBKACy64gOXLlzNnzpxx2Slq7tXpuli6dKmvWbNmn9570jfu4vA5U7n8vDeOcVUi8mq3bt06Dj/88GqXMSGGWlYze2i4831S2eWSCwPdsUhEZJBUBnomNIq6p6iIyC5SGejqQxeZ3KrVVTyR9mUZ0xnogQJdZLKqq6tjy5YtNR3q7s6WLVuoq6vbq/el8iiXTGj0qQ9dZFKaP38+ra2t7Otdz9Kirq6O+fP37o6eqQz0bBjQ2VusdhkiUgXZbJZFixZVu4xXpXR2uYSmG1yIiAyS0kBXH7qIyGCpDPRMGOiwRRGRQVIZ6HGXi1roIiKV0hnoOmxRRGQ3qQz0TKgbXIiIDJbKQNct6EREdpfSQFcLXURksBED3cxWmdkmM1s7zHgzs2+b2Xoze9TMxv2attkwoBiphS4iUmk0LfTvAqfvYfxyYHHyuAC4cv/L2rNMGFAoeU1fy0FEZG+NGOjufjfwyh4mWQF832P3A9PNbM5YFTiUXGgAOhZdRKTCWPShzwM2VLxuTYbtxswuMLM1ZrZmfy6skwnjsnXooojIgLEIdBti2JBNZ3e/yt2XuvvSlpaWff7ATBB/pK7nIiIyYCwCvRU4qOL1fKBtDOY7rFxGLXQRkcHGItBvBt6fHO1yHLDd3V8ag/kOKxPEZevQRRGRASNeD93MrgOWATPNrBX4IpAFcPeVwGrgDGA90AV8aLyKLcuG5S4XtdBFRMpGDHR3P3eE8Q58YswqGoWsdoqKiOwmpWeKJl0uOmxRRKRfKgM9k3S56L6iIiIDUhnoWZ1YJCKym5QGuvrQRUQGS2Wglw9bVKCLiAxIZaDnMkmXi45DFxHpl8pAVwtdRGR36Qz0UNdyEREZLJWBntNOURGR3aQy0DP9JxYp0EVEylIZ6P3Xcimqy0VEpCylgZ50uaiFLiLSL9WBrsMWRUQGpDLQM7p8rojIblIZ6Nn+49DVQhcRKUtnoKuFLiKym1QGehiUT/1XoIuIlKUy0M2MXBjQpy4XEZF+qQx0iHeMqoUuIjIgtYGeDQPd4EJEpEKKA93oUwtdRKRfagM9EwTqchERqTCqQDez083sSTNbb2YXDTF+mpn91Mx+Z2aPmdmHxr7UXWUzpuPQRUQqjBjoZhYClwPLgSXAuWa2ZNBknwAed/ejgGXAN8wsN8a17iIbBDoOXUSkwmha6McC6939WXfvA64HVgyaxoEpZmZAE/AKUBzTSgfJhgp0EZFKown0ecCGitetybBK/wocDrQBvwc+4+7jmrbxYYvqchERKRtNoNsQwwYn6WnAI8Bc4GjgX81s6m4zMrvAzNaY2Zr29va9LHVX2TCgoMMWRUT6jSbQW4GDKl7PJ26JV/oQcKPH1gPPAa8bPCN3v8rdl7r70paWln2tGYgPWywU1eUiIlI2mkB/EFhsZouSHZ3nADcPmuYPwMkAZjYbOAx4diwLHSwTBLoFnYhIhcxIE7h70cw+CdwGhMAqd3/MzD6ejF8JfAX4rpn9nriL5kJ33zyOdZPNBHR1l8bzI0REUmXEQAdw99XA6kHDVlY8bwPeMbal7Vk20LVcREQqpfZMUR22KCKyq9QGug5bFBHZVWoDPRcGFLRTVESkX2oDPRMahaJa6CIiZSkOdB22KCJSKbWBngsD+nRikYhIv9QGeiYw3bFIRKRCagM9mwl0lIuISIX0BnoQ34LOXaEuIgIpDvRMGJdeUreLiAiQ4kDPJoGu29CJiMRSHOjxZdp1cpGISCzFgZ600HXooogIkOJAzyQtdB26KCISS22gD/Shq4UuIgKpDvSkD107RUVEgBQHeiaIS9dNLkREYqkN9HKXS58CXUQESHWgJztF1eUiIgKkOtC1U1REpFJqAz2jnaIiIrtIbaDnkha6bnIhIhLLVLuAvda5GTauJcdrAXW5iIiUjaqFbmanm9mTZrbezC4aZpplZvaImT1mZv8ztmVWeO5u+P4K6jtbAXW5iIiUjdhCN7MQuBw4FWgFHjSzm9398YpppgNXAKe7+x/MbNY41Qv5KfE/URegFrqISNloWujHAuvd/Vl37wOuB1YMmuY84EZ3/wOAu28a2zIr5JoAyJbiQNdhiyIisdEE+jxgQ8Xr1mRYpdcCM8zsLjN7yMzeP9SMzOwCM1tjZmva29v3reJ8EujFDkAnFomIlI0m0G2IYYObxRngTcCZwGnAF8zstbu9yf0qd1/q7ktbWlr2uligv8slW1QLXUSk0miOcmkFDqp4PR9oG2Kaze7eCXSa2d3AUcBTY1JlpVwc6JliJ9CiwxZFRBKjaaE/CCw2s0VmlgPOAW4eNM1NwB+ZWcbMGoC3AOvGttRE0uUSFjsB6NMNLkREgFG00N29aGafBG4DQmCVuz9mZh9Pxq9093Vm9t/Ao0AEXO3ua8en4jwEWcJC3IeuG1yIiMRGdWKRu68GVg8atnLQ668DXx+70vYg30RQiFvougWdiEgsnaf+56YQJC30glroIiJAWgM934T1dpANTScWiYgk0hnouSbo6yATBLpjkYhIIp2Bnm+C3g4yoelaLiIiiXQGetJCz4WBulxERBLpDPT8lP4Wus4UFRGJpTPQc03Qt5OsWugiIv3SGehJH3o2MB22KCKSSGeg55rASzSGBZ1YJCKSSGegJ1dcnGK9ujiXiEginYGe3ORiatCtwxZFRBLpDPTkiotTrUc7RUVEEukM9KSF3mg9OmxRRCSRzkBP+tCbrEe3oBMRSaQz0JMWehM92ikqIpJIZ6Dny10u3epyERFJpDTQ4y6XBrrV5SIikkhnoCddLg2uFrqISFk6Az0IIdtAg3frsEURkUQ6Ax0g10Sd68QiEZGy9AZ6vol6tdBFRPqlN9BzTdRFXboFnYhIYlSBbmanm9mTZrbezC7aw3RvNrOSmf3J2JU4jPwU6qJuXT5XRCQxYqCbWQhcDiwHlgDnmtmSYab7J+C2sS5ySLkm8lGXulxERBKjaaEfC6x392fdvQ+4HlgxxHSfAm4ANo1hfcPLN5ErdeEOJbXSRURGFejzgA0Vr1uTYf3MbB7wHmDl2JU2glwTuagTQK10ERFGF+g2xLDBTeJvARe6e2mPMzK7wMzWmNma9vb2UZY4jPwUckUFuohIWWYU07QCB1W8ng+0DZpmKXC9mQHMBM4ws6K7/1flRO5+FXAVwNKlS/evnyTXRDbqISDSsegiIowu0B8EFpvZIuBF4BzgvMoJ3H1R+bmZfRf42eAwH3PlC3TRo0MXRUQYRaC7e9HMPkl89EoIrHL3x8zs48n4ies3r1S+yQU6dFFEBEbXQsfdVwOrBw0bMsjd/YP7X9YoJFdcbLQeCkW10EVEUn2mKEAT3brJhYgIaQ70/MB9RfuK6nIREUlvoKuFLiKyi/QGerkPnR4dhy4iQpoDPTfQ5dLZu8fzmUREJoX0Bnp+oMvl5e09VS5GRKT60hvo2QbcApqshxe3dVe7GhGRqktvoJthuSm05PpoU6CLiIzuxKJXrXwTM61A23YFuohIugM918SMqI+2bepDFxFJb5cLQL6JaUEPbdu6cdfJRSIyuaU70HNNTLFueosRr3T2VbsaEZGqSneg56dQ73F3i7pdRGSyS3egJzeKBnTooohMeukO9HwTmeQ2dDp0UUQmu3QHeq4J6+ugLhso0EVk0kt3oOebsKjAwdMyOhZdRCa9dAd6Lr7i4iFTnRe1U1REJrl0B3pyga6DmyJ1uYjIpJfuQE8uoTu/sUT7zl56i7qMrohMXukO9OQmF/PqegHYuL23mtWIiFRVugN99hEALOpZB+hYdBGZ3NId6FNmw6wlzN58H6Bj0UVkchtVoJvZ6Wb2pJmtN7OLhhj/Z2b2aPK418yOGvtSh7HobdS99CB5dF10EZncRgx0MwuBy4HlwBLgXDNbMmiy54C3ufuRwFeAq8a60GEdsgwr9vD2hud0LLqITGqjaaEfC6x392fdvQ+4HlhROYG73+vuW5OX9wPzx7bMPVh4AljIyfl1OhZdRCa10QT6PGBDxevWZNhwPgLcOtQIM7vAzNaY2Zr29vbRV7kn+Skw/80sjR5Vl4uITGqjCXQbYtiQd5Mws7cTB/qFQ41396vcfam7L21paRl9lSM5ZBkH9z5Fx7Z23ehCRCat0QR6K3BQxev5QNvgiczsSOBqYIW7bxmb8kbpkGUERBxVXMuO7uKEfrSIyKvFaAL9QWCxmS0ysxxwDnBz5QRmtgC4EXifuz819mWOYN6bKIYNnBCs1bHoIjJpjRjo7l4EPgncBqwDfuTuj5nZx83s48lklwDNwBVm9oiZrRm3ioeSydE19y2cEKzl2c0dE/rRIiKvFpnRTOTuq4HVg4atrHj+UeCjY1va3ml83SlM3XAnqx7+He88cm41SxERqYp0nylaIXztqQAc9exVbO8uVLkaEZGJVzOBTsthbDzqE5wd3MG6W/+t2tWIiEy42gl0YNa7L+W34REc8+iXYePj1S5HRGRC1VSgW5jl4aX/zHavp3D9+6B3Z7VLEhGZMDUV6ACnHnsUn+r7FOHW5+AH/wu6t478JhGRGlBzgb6guYHSgrfylfrP4y89At85E3ZurHZZIiLjruYCHeCsY+bxna1H8tw7vgNbn4dVp8GWZ6pdlojIuKrJQH/XkXOZVp/lY79qouNPb4i7Xf7tj+G3PwRd60VEalRNBvq0hiz/9r438YdXuvjYHUbfx+6BOUfDTX8J//kB6JzYS82IiEyEmgx0gOMOaeZrf3Ik9z27hb+5Yyv+/pvglC/BE7fAt4+Ge74BfV3VLlNEZMzUbKADvOeY+Xz2lMX8+KFWvvbz9fgJn4WP/xoWngi//DJ8+xh46HsQlapdqojIfqvpQAf4zMmLOe8tC7jyrmf42m1P4i2HwbnXwYf+G2YcDD/9NKz8I3jmjmqXKiKyX0Z1ca40MzP+fsURGHDlXc8QuXPR6a/DDj4ePnwbPH4T/PwS+MF7YMHxcPR5sGQF1E2rdukiInvFqnWHn6VLl/qaNRN3lV1355KbHuMH97/A8Yc0c86xB3Ha6w+kLhtCsRcevBrWrIIt6yFTB4eeAq85CV7zdjjgkAmrU0RkT8zsIXdfOuS4yRLoEIf61fc8x/fue57Wrd1MyWc477gF/OWyQ5lWn40PaXzxYfjdtfDUbbA9uZVq86Hw+vfEj1lLwIa6K5+IyPhToA8SRc79z23hugc28LNH25hWn+XTJy3m/OMOJpdJdiu4xycjPXMHPHkLPHc3eARNB0LTLGicCVPnwYLj4OC3woxFCnoRGXcK9D14rG07X129jl+v30JjLuS4Q5p566EzWXZYC69paRqYsKMd1t0Ut+A7N0PXZnjl2YFrxTTNhgPfED9mHwEHHgnNr4EgrM6CiUhNUqCPwN359fot3Lr2Je59ZgvPbe4EYPGsJpYfcSDveP2BLJkzlSAY1AKPItj8JLxwL2x4ADauhfYnIEpuVJ2ph5bXQv0MyDVB3XSYvQTmvhHmHAm5xoldUBFJPQX6Xmrd2sUv123i1rUv8cBzrxA5zGzKceKhMzlmwQya8hkaciGzptZx9EHTCSuDvtgL7U/G4f7y72HzU9CzA/o6oGsLdFRcKCw/FfJT4ke2Pl4BZOth6lyYuRiaF8f99zMWQiY34d+DiLz6KND3w+aOXu5+qp27n2rnnqc3s6Wzb5fxs6bkWX7EgZx8+Gzmz6inZUqepnwGG64/fedGaPstvPwodL0SX7O9dzsUuuOVQV9nvDO2s33gPRbA9AVx8JeKEBUgyELd1Hil0HAATDkQpsyBhuaBlUOuIT78sm5avIUQ5iDMQpBRf79ISinQx0gUOa909dHVW6Kzr8jTmzpY/ehL3PnkJnqLUf90DbmQedPrmT+jnrnT62luytPcmKO5KcfsqXUcOLWOWVPz5DN76F/v3hYfQrnlmeTf9VDoisM4zEKpkKwMdsQt/50vQ6lv+PntxuJQtxDyTcmWwjSYNg+mHxz/61G8oil0xZ9V3tJoaI63GqYfHL+3f5ZBvKIJwngl0jQ7foTZeGVV6IqnqZumFYrIPlKgj7OO3iKP/GEbm3b20L6zl5d39NC2rZvWrd20betmW3dhyIs8NuZCptVnmVqfpTHpxqnPxsNmNOaY0ZCjMR+SzwTkMyENuZCp9Vmm1GVoymeoy4bUZUNyYUBgTtCzjUzvVqzYEwdxX0ccwr074kAuFeJHVIiP4vEo7u/v60wCextsb4WtL0Bfxd2eMvVx4NdNjfv9OzfDjjZglH87FoJXXF4hyEJjS7JvoQGyDXHo93XFoR+VoH56PD7bADvb4rq6tsTnBMw+AlpeF6/cSr3xMmXq4i2TXGP8eZassMrDsw0DWyblFU+mDjL5eDieXInTB67IGWTi+eWaIAji4VEp/t7C7N6vlKISFHviWrRCk32034FuZqcD/wKEwNXuftmg8ZaMPwPoAj7o7g/vaZ61FOgjKZYitnUX2NLRx8YdPby8o4eN23vY1l1gW1eB7d0FuvqKdPWV6O4rsb27wCtdffRVtPpHKwyMafVZptdnmdaQpTlZMUytz5IJjUxghGaU3ClF4Dj5TLwiqcsG1GdD6rMBjdZDQ76OhsZGGvMZipHTW4zoK0bUZQOm5SKm927EC130FiN6ixFGRH0YUWdOtrCDsGsTQedGrNSH5Rog2xivQLo2x0cNdW+FQmcc5FEhHp9Lgrd7a9wlVeiKu5KmHxTvVN6yPt4/0TXBV8wMsnGN/WxghWBB8jD6t3yweCUWleJ/C90DW1CZOpg2Pz7sNdtQMc+KlYkF8UojzCajonheQTjwPYWD9qt4lDzK80i2wLLJvpkgjL/3jo3x99vQDFPnQOOsuLa+zvj7DnPxiizbEP9exd54RQTxPILMwJZimBtYgZbrDsJ4WHmaTH5guiCMl7PQnXwnhXgrL9c0cJBAubFR7Ik/u9QXL29+WtywwAcaJr0dyZbqzvj9TbPixkKYjWuPSvFvESY1F3vjhkv3tvhz6qYO7MOyYNffr/+nDioaAskyBdlBv1s0UHdlQydIvqOw4qT8yt9nH+wp0Ec89d/MQuBy4FSgFXjQzG5298q7MC8HFiePtwBXJv8KkAkDZjblmdmU57ADp4zqPe5Od6FEV1+J3mJET6FEV2+JnT0FdvQU6Owt0VMs0VOIKJQiSpETRU5PMV4hbOsqsLWrj7ZtPTzWtoMd3QWKkVOMnFLkhEmwY+zTimN0WoAWwsD6Vxi5MCAILP78IF7BZIKATGhYwQi743d29ZXoLpToKZSwbsPaITAjnwnIZY2ZzV3kMgGZbJ4wk6MxLNIUFGgK+shaRGAQmJOjQN57yUU9ZKxEaEbGIkJKZKNeMlFvvHVjhpnhGMUIiiUn8CL19NDgXWQp4kEGD3Jxlkd9ZLyPsNSL4cRRECUx4BhOiYCiGyUComSHt2XqqOt9hfqel6jf+TJBtLn8i2P93WCGeYRFBYLySsRCPAixqIgVugiKXVipj8rg8SAcCCUccwcvYcVuzOPfOMrUEzXOJqqbRtD+FGHHRiyKVzRuAZ5tiFfAg7rvPMjE842K2Gi3zGSAlc9vSf6vnfBZOPXSMf+Y0VzL5Vhgvbs/C2Bm1wMrgMpAXwF83+Pm/v1mNt3M5rj7S2Ne8SRhZjTkMjTkxv9yO1HS+i4HaE+yIunsLdLZV6Sjt0Q2MPLZgFwY0lMosaMn3rIILAnrXEgUDayE+ooRkTvFktNXilc83YVkeOSUPF65RJFTKDmlKKLkcS0AzU15GnIhdcl+hsidyKGvFNFbKNFTrKezUKK3N6Kno0hfMaK3aPQWs5SiiCiZV+QZIq+n5PFnFaPJGEZOlhIhJXrIQ8eu46bSRS9ZeslCd7yCyFCkgV6KhPQm7y4zIjJEZCmSpUhIlKzU4i6rkIgAJ2MlshTJU+ifLiQOtC7y9JCjSEgjPUwJemmy3riBnMythww9nqNAhgZ6aKKTRrqTFnNIFGTopJ6d3kCH15ErdTHNtzGT7YQWUfQQC0IyAWQtIhdEFMiwk0Z20EjRjYaoi3rvIk8v2cDIBE5olffB8f5lCy3+HrNWImdR+cvAMEoer87dISJIGt9O1iKyFMhTBAw3gICZXYdxxjj80qNJi3nAhorXreze+h5qmnmAAj0FgsCoz4XU52r/JCj3eAsl8ri7yT1eWZSSLRfDyGWC/jOGe5OtoL5ihOP9K4r+97njycqmVDEciOcTxlsfUQR9pRJ9RacYxVtVhZIT+cB7yvMuRuXhA91i7vGGvLtjZhi7b7GXQ6g8z1Ky4sSJV2iebIlQ3hCw/tfl76AQxd0+/cuTfGZlz6xXtNDd426+fPKduQ9sXRVL3t/NZwalaOBzdq3Vd+kCJPk+ystZDs3y8pYbCqXIaS4vS/K7DdTh9JWcvmJEsRQl84+3pKYlj8CSLsgwnnGx5BRKEX2RE1R8pid/K/FXU/5bqfhdfGALr1xj+T1U/Lae1I7DqQtm7/8f8xBGE+hDdfQMbuaMZhrM7ALgAoAFCxaM4qNFxpaZkQlH33cZbyWNY0EiY2g010NvBQ6qeD0faNuHaXD3q9x9qbsvbWlp2dtaRURkD0YT6A8Ci81skZnlgHOAmwdNczPwfosdB2xX/7mIyMQascvF3Ytm9kngNuLDFle5+2Nm9vFk/EpgNfEhi+uJD1v80PiVLCIiQxnVIRTuvpo4tCuHrax47sAnxrY0ERHZGzV/T1ERkclCgS4iUiMU6CIiNUKBLiJSI6p2tUUzawde2Me3zwQ2jzhV7ZmMyz0Zlxkm53JPxmWGvV/ug919yBN5qhbo+8PM1gx3tbFaNhmXezIuM0zO5Z6Mywxju9zqchERqREKdBGRGpHWQL+q2gVUyWRc7sm4zDA5l3syLjOM4XKnsg9dRER2l9YWuoiIDKJAFxGpEakLdDM73cyeNLP1ZnZRtesZD2Z2kJndaWbrzOwxM/tMMvwAM/u5mT2d/Duj2rWONTMLzey3Zvaz5PVkWObpZvZjM3si+c2PnyTL/X+Sv++1ZnadmdXV2nKb2Soz22RmayuGDbuMZnZxkm1Pmtlpe/t5qQr0ihtWLweWAOea2ZLqVjUuisBfufvhwHHAJ5LlvAj4pbsvBn6ZvK41nwHWVbyeDMv8L8B/u/vrgKOIl7+ml9vM5gGfBpa6+xHEl+Y+h9pb7u8Cpw8aNuQyJv/HzwFen7zniiTzRi1VgU7FDavdvQ8o37C6prj7S+7+cPJ8J/F/8HnEy/q9ZLLvAWdVpcBxYmbzgTOBqysG1/oyTwX+GPgPAHfvc/dt1PhyJzJAvZllgAbiu5zV1HK7+93AK4MGD7eMK4Dr3b3X3Z8jvr/EsXvzeWkL9OFuRl2zzGwhcAzwG2B2+U5Qyb+zqljaePgW8NeQ3Bo+VuvLfAjQDnwn6Wq62swaqfHldvcXgX8G/kB8M/nt7n47Nb7cieGWcb/zLW2BPqqbUdcKM2sCbgA+6+47ql3PeDKzdwKb3P2hatcywTLAG4Er3f0YoJP0dzOMKOk3XgEsAuYCjWZ2fnWrqrr9zre0BfqobkZdC8wsSxzmP3T3G5PBG81sTjJ+DrCpWvWNgxOAd5vZ88RdaSeZ2TXU9jJD/Dfd6u6/SV7/mDjga325TwGec/d2dy8ANwJvpfaXG4Zfxv3Ot7QF+mhuWJ16ZmbEfarr3P2bFaNuBj6QPP8AcNNE1zZe3P1id5/v7guJf9c73P18aniZAdz9ZWCDmR2WDDoZeJwaX27irpbjzKwh+Xs/mXhfUa0vNwy/jDcD55hZ3swWAYuBB/Zqzu6eqgfxzaifAp4B/rba9YzTMp5IvKn1KPBI8jgDaCbeK/508u8B1a51nJZ/GfCz5HnNLzNwNLAm+b3/C5gxSZb7UuAJYC3wAyBfa8sNXEe8j6BA3AL/yJ6WEfjbJNueBJbv7efp1H8RkRqRti4XEREZhgJdRKRGKNBFRGqEAl1EpEYo0EVEaoQCXUSkRijQRURqxP8Hbi4IkIwQgcYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# mlp with scaled outputs on the regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "# created scaler\n",
    "scaler = StandardScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "# evaluate the model\n",
    "train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "test_mse = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3c3dd8d8",
   "metadata": {},
   "source": [
    "Running the example fits the model and calculates the mean squared error on the train and test sets.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "In this case, the model does appear to learn the problem and achieves near-zero mean squared error, at least to three decimal places.\n",
    "\n",
    "Train: 0.003, Test: 0.007\n",
    "A line plot of the mean squared error on the train (blue) and test (orange) dataset over each training epoch is created.\n",
    "\n",
    "In this case, we can see that the model rapidly learns to effectively map inputs to outputs for the regression problem and achieves good performance on both datasets over the course of the run, neither overfitting or underfitting the training dataset.\n",
    "\n",
    "It may be interesting to repeat this experiment and normalize the target variable instead and compare results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a663773b",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron With Scaled Input Variables"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fc2684c7",
   "metadata": {},
   "source": [
    "\n",
    "We have seen that data scaling can stabilize the training process when fitting a model for regression with a target variable that has a wide spread.\n",
    "\n",
    "It is also possible to improve the stability and performance of the model by scaling the input variables.\n",
    "\n",
    "In this section, we will design an experiment to compare the performance of different scaling methods for the input variables.\n",
    "\n",
    "The input variables also have a Gaussian data distribution, like the target variable, therefore we would expect that standardizing the data would be the best approach. This is not always the case.\n",
    "\n",
    "We can compare the performance of the unscaled input variables to models fit with either standardized and normalized input variables.\n",
    "\n",
    "The first step is to define a function to create the same 1,000 data samples, split them into train and test sets, and apply the data scaling methods specified via input arguments. The get_dataset() function below implements this, requiring the scaler to be provided for the input and target variables and returns the train and test datasets split into input and output components ready to train and evaluate a model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb737ed6",
   "metadata": {},
   "source": [
    "\n",
    "# prepare dataset with input and output scalers, can be none\n",
    "def get_dataset(input_scaler, output_scaler):\n",
    "\t# generate dataset\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "\t# split into train and test\n",
    "\tn_train = 500\n",
    "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "\ttrainy, testy = y[:n_train], y[n_train:]\n",
    "\t# scale inputs\n",
    "\tif input_scaler is not None:\n",
    "\t\t# fit scaler\n",
    "\t\tinput_scaler.fit(trainX)\n",
    "\t\t# transform training dataset\n",
    "\t\ttrainX = input_scaler.transform(trainX)\n",
    "\t\t# transform test dataset\n",
    "\t\ttestX = input_scaler.transform(testX)\n",
    "\tif output_scaler is not None:\n",
    "\t\t# reshape 1d arrays to 2d arrays\n",
    "\t\ttrainy = trainy.reshape(len(trainy), 1)\n",
    "\t\ttesty = testy.reshape(len(trainy), 1)\n",
    "\t\t# fit scaler on training dataset\n",
    "\t\toutput_scaler.fit(trainy)\n",
    "\t\t# transform training dataset\n",
    "\t\ttrainy = output_scaler.transform(trainy)\n",
    "\t\t# transform test dataset\n",
    "\t\ttesty = output_scaler.transform(testy)\n",
    "\treturn trainX, trainy, testX, testy\n",
    "Next, we can define a function to fit an MLP model on a given dataset and return the mean squared error for the fit model on the test dataset.\n",
    "\n",
    "The evaluate_model() function below implements this behavior.\n",
    "\n",
    "# fit and evaluate mse of model on test set\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer=SGD(lr=0.01, momentum=0.9))\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\t# evaluate the model\n",
    "\ttest_mse = model.evaluate(testX, testy, verbose=0)\n",
    "\treturn test_mse\n",
    "Neural networks are trained using a stochastic learning algorithm. This means that the same model fit on the same data may result in a different performance.\n",
    "\n",
    "We can address this in our experiment by repeating the evaluation of each model configuration, in this case a choice of data scaling, multiple times and report performance as the mean of the error scores across all of the runs. We will repeat each run 30 times to ensure the mean is statistically robust.\n",
    "\n",
    "The repeated_evaluation() function below implements this, taking the scaler for input and output variables as arguments, evaluating a model 30 times with those scalers, printing error scores along the way, and returning a list of the calculated error scores from each run.\n",
    "\n",
    "# evaluate model multiple times with given input and output scalers\n",
    "def repeated_evaluation(input_scaler, output_scaler, n_repeats=30):\n",
    "\t# get dataset\n",
    "\ttrainX, trainy, testX, testy = get_dataset(input_scaler, output_scaler)\n",
    "\t# repeated evaluation of model\n",
    "\tresults = list()\n",
    "\tfor _ in range(n_repeats):\n",
    "\t\ttest_mse = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tprint('>%.3f' % test_mse)\n",
    "\t\tresults.append(test_mse)\n",
    "\treturn results\n",
    "Finally, we can run the experiment and evaluate the same model on the same dataset three different ways:\n",
    "\n",
    "No scaling of inputs, standardized outputs.\n",
    "Normalized inputs, standardized outputs.\n",
    "Standardized inputs, standardized outputs.\n",
    "The mean and standard deviation of the error for each configuration is reported, then box and whisker plots are created to summarize the error scores for each configuration.\n",
    "\n",
    "# unscaled inputs\n",
    "results_unscaled_inputs = repeated_evaluation(None, StandardScaler())\n",
    "# normalized inputs\n",
    "results_normalized_inputs = repeated_evaluation(MinMaxScaler(), StandardScaler())\n",
    "# standardized inputs\n",
    "results_standardized_inputs = repeated_evaluation(StandardScaler(), StandardScaler())\n",
    "# summarize results\n",
    "print('Unscaled: %.3f (%.3f)' % (mean(results_unscaled_inputs), std(results_unscaled_inputs)))\n",
    "print('Normalized: %.3f (%.3f)' % (mean(results_normalized_inputs), std(results_normalized_inputs)))\n",
    "print('Standardized: %.3f (%.3f)' % (mean(results_standardized_inputs), std(results_standardized_inputs)))\n",
    "# plot results\n",
    "results = [results_unscaled_inputs, results_normalized_inputs, results_standardized_inputs]\n",
    "labels = ['unscaled', 'normalized', 'standardized']\n",
    "pyplot.boxplot(results, labels=labels)\n",
    "pyplot.show()\n",
    "Tying these elements together, the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4e00068b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.012\n",
      ">0.011\n",
      ">0.004\n",
      ">0.011\n",
      ">0.002\n",
      ">0.004\n",
      ">0.006\n",
      ">0.007\n",
      ">0.003\n",
      ">0.009\n",
      ">0.003\n",
      ">0.006\n",
      ">0.005\n",
      ">0.012\n",
      ">0.014\n",
      ">0.015\n",
      ">0.005\n",
      ">0.012\n",
      ">0.006\n",
      ">0.006\n",
      ">0.002\n",
      ">0.010\n",
      ">0.005\n",
      ">0.008\n",
      ">0.013\n",
      ">0.011\n",
      ">0.012\n",
      ">0.009\n",
      ">0.004\n",
      ">0.011\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.003\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.003\n",
      ">0.010\n",
      ">0.005\n",
      ">0.006\n",
      ">0.013\n",
      ">0.006\n",
      ">0.008\n",
      ">0.008\n",
      ">0.005\n",
      ">0.002\n",
      ">0.002\n",
      ">0.008\n",
      ">0.010\n",
      ">0.002\n",
      ">0.006\n",
      ">0.009\n",
      ">0.007\n",
      ">0.007\n",
      ">0.000\n",
      ">0.007\n",
      ">0.014\n",
      ">0.008\n",
      ">0.002\n",
      ">0.001\n",
      ">0.000\n",
      ">0.004\n",
      ">0.008\n",
      ">0.006\n",
      ">0.010\n",
      "Unscaled: 0.008 (0.004)\n",
      "Normalized: 0.001 (0.001)\n",
      "Standardized: 0.006 (0.004)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# compare scaling methods for mlp inputs on regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    " \n",
    "# prepare dataset with input and output scalers, can be none\n",
    "def get_dataset(input_scaler, output_scaler):\n",
    "\t# generate dataset\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "\t# split into train and test\n",
    "\tn_train = 500\n",
    "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "\ttrainy, testy = y[:n_train], y[n_train:]\n",
    "\t# scale inputs\n",
    "\tif input_scaler is not None:\n",
    "\t\t# fit scaler\n",
    "\t\tinput_scaler.fit(trainX)\n",
    "\t\t# transform training dataset\n",
    "\t\ttrainX = input_scaler.transform(trainX)\n",
    "\t\t# transform test dataset\n",
    "\t\ttestX = input_scaler.transform(testX)\n",
    "\tif output_scaler is not None:\n",
    "\t\t# reshape 1d arrays to 2d arrays\n",
    "\t\ttrainy = trainy.reshape(len(trainy), 1)\n",
    "\t\ttesty = testy.reshape(len(trainy), 1)\n",
    "\t\t# fit scaler on training dataset\n",
    "\t\toutput_scaler.fit(trainy)\n",
    "\t\t# transform training dataset\n",
    "\t\ttrainy = output_scaler.transform(trainy)\n",
    "\t\t# transform test dataset\n",
    "\t\ttesty = output_scaler.transform(testy)\n",
    "\treturn trainX, trainy, testX, testy\n",
    " \n",
    "# fit and evaluate mse of model on test set\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\t# evaluate the model\n",
    "\ttest_mse = model.evaluate(testX, testy, verbose=0)\n",
    "\treturn test_mse\n",
    " \n",
    "# evaluate model multiple times with given input and output scalers\n",
    "def repeated_evaluation(input_scaler, output_scaler, n_repeats=30):\n",
    "\t# get dataset\n",
    "\ttrainX, trainy, testX, testy = get_dataset(input_scaler, output_scaler)\n",
    "\t# repeated evaluation of model\n",
    "\tresults = list()\n",
    "\tfor _ in range(n_repeats):\n",
    "\t\ttest_mse = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tprint('>%.3f' % test_mse)\n",
    "\t\tresults.append(test_mse)\n",
    "\treturn results\n",
    " \n",
    "# unscaled inputs\n",
    "results_unscaled_inputs = repeated_evaluation(None, StandardScaler())\n",
    "# normalized inputs\n",
    "results_normalized_inputs = repeated_evaluation(MinMaxScaler(), StandardScaler())\n",
    "# standardized inputs\n",
    "results_standardized_inputs = repeated_evaluation(StandardScaler(), StandardScaler())\n",
    "# summarize results\n",
    "print('Unscaled: %.3f (%.3f)' % (mean(results_unscaled_inputs), std(results_unscaled_inputs)))\n",
    "print('Normalized: %.3f (%.3f)' % (mean(results_normalized_inputs), std(results_normalized_inputs)))\n",
    "print('Standardized: %.3f (%.3f)' % (mean(results_standardized_inputs), std(results_standardized_inputs)))\n",
    "# plot results\n",
    "results = [results_unscaled_inputs, results_normalized_inputs, results_standardized_inputs]\n",
    "labels = ['unscaled', 'normalized', 'standardized']\n",
    "pyplot.boxplot(results, labels=labels)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "34baeaaf",
   "metadata": {},
   "source": [
    "Running the example prints the mean squared error for each model run along the way.\n",
    "\n",
    "After each of the three configurations have been evaluated 30 times each, the mean errors for each are reported.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "In this case, we can see that as we expected, scaling the input variables does result in a model with better performance. Unexpectedly, better performance is seen using normalized inputs instead of standardized inputs. This may be related to the choice of the rectified linear activation function in the first hidden layer.\n",
    "\n",
    "...\n",
    ">0.010\n",
    ">0.012\n",
    ">0.005\n",
    ">0.008\n",
    ">0.008\n",
    "Unscaled: 0.007 (0.004)\n",
    "Normalized: 0.001 (0.000)\n",
    "Standardized: 0.008 (0.004)\n",
    "A figure with three box and whisker plots is created summarizing the spread of error scores for each configuration.\n",
    "\n",
    "The plots show that there was little difference between the distributions of error scores for the unscaled and standardized input variables, and that the normalized input variables result in better performance and more stable or a tighter distribution of error scores.\n",
    "\n",
    "These results highlight that it is important to actually experiment and confirm the results of data scaling methods rather than assuming that a given data preparation scheme will work best based on the observed distribution of the data.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f6f1138",
   "metadata": {},
   "source": [
    "# Extensions"
   ]
  },
  {
   "cell_type": "raw",
   "id": "37de84de",
   "metadata": {},
   "source": [
    "\n",
    "This section lists some ideas for extending the tutorial that you may wish to explore.\n",
    "\n",
    "Normalize Target Variable. Update the example and normalize instead of standardize the target variable and compare results.\n",
    "\n",
    "Compared Scaling for Target Variable. Update the example to compare standardizing and normalizing the target variable using repeated experiments and compare the results.\n",
    "\n",
    "Other Scales. Update the example to evaluate other min/max scales when normalizing and compare performance, e.g. [-1, 1] and [0.0, 0.5]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b50e2be",
   "metadata": {},
   "source": [
    "# Normalize Target Variable. Update the example and normalize instead of standardize the target variable and compare results.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8710309d",
   "metadata": {},
   "source": [
    "# Multilayer Perceptron With Scaled Output Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a5328787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.002, Test: 0.003\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# mlp with scaled outputs on the regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "# generate regression dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "# split into train and test\n",
    "n_train = 500\n",
    "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "trainy, testy = y[:n_train], y[n_train:]\n",
    "# reshape 1d arrays to 2d arrays\n",
    "trainy = trainy.reshape(len(trainy), 1)\n",
    "testy = testy.reshape(len(trainy), 1)\n",
    "# created scaler\n",
    "scaler = MinMaxScaler()\n",
    "# fit scaler on training dataset\n",
    "scaler.fit(trainy)\n",
    "# transform training dataset\n",
    "trainy = scaler.transform(trainy)\n",
    "# transform test dataset\n",
    "testy = scaler.transform(testy)\n",
    "# define model\n",
    "model = Sequential()\n",
    "model.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "# compile model\n",
    "model.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
    "# fit model\n",
    "history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=100, verbose=0)\n",
    "# evaluate the model\n",
    "train_mse = model.evaluate(trainX, trainy, verbose=0)\n",
    "test_mse = model.evaluate(testX, testy, verbose=0)\n",
    "print('Train: %.3f, Test: %.3f' % (train_mse, test_mse))\n",
    "# plot loss during training\n",
    "pyplot.title('Loss / Mean Squared Error')\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c7b13dd2",
   "metadata": {},
   "source": [
    "# Mean squared errors were comparably lower for the train and test models when ran with normaized target feature Vs standardised target feature (Train: 0.002, Test: 0.003 Vs. Train: 0.004, Test: 0.011)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ef2be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2faf4a6",
   "metadata": {},
   "source": [
    "# Compared Scaling for Target Variable. Update the example to compare standardizing and normalizing the target variable using repeated experiments and compare the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "636559ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.008\n",
      ">0.005\n",
      ">0.006\n",
      ">0.012\n",
      ">0.001\n",
      ">0.006\n",
      ">0.003\n",
      ">0.011\n",
      ">0.006\n",
      ">0.001\n",
      ">0.011\n",
      ">0.000\n",
      ">0.012\n",
      ">0.009\n",
      ">0.005\n",
      ">0.011\n",
      ">0.008\n",
      ">0.010\n",
      ">0.008\n",
      ">0.006\n",
      ">0.007\n",
      ">0.002\n",
      ">0.010\n",
      ">0.007\n",
      ">0.007\n",
      ">0.006\n",
      ">0.008\n",
      ">0.006\n",
      ">0.012\n",
      ">0.013\n",
      ">0.004\n",
      ">0.002\n",
      ">0.003\n",
      ">0.004\n",
      ">0.003\n",
      ">0.004\n",
      ">0.003\n",
      ">0.003\n",
      ">0.004\n",
      ">0.005\n",
      ">0.003\n",
      ">0.004\n",
      ">0.004\n",
      ">0.004\n",
      ">0.004\n",
      ">0.004\n",
      ">0.004\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.004\n",
      ">0.003\n",
      ">0.004\n",
      ">0.003\n",
      ">0.004\n",
      ">0.004\n",
      ">0.003\n",
      ">0.003\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.002\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.001\n",
      ">0.002\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.010\n",
      ">0.001\n",
      ">0.002\n",
      ">0.000\n",
      ">0.000\n",
      ">0.002\n",
      ">0.009\n",
      ">0.005\n",
      ">0.003\n",
      ">0.004\n",
      ">0.007\n",
      ">0.010\n",
      ">0.005\n",
      ">0.010\n",
      ">0.013\n",
      ">0.004\n",
      ">0.009\n",
      ">0.005\n",
      ">0.009\n",
      ">0.011\n",
      ">0.004\n",
      ">0.007\n",
      ">0.006\n",
      ">0.006\n",
      ">0.007\n",
      ">0.011\n",
      ">0.003\n",
      ">0.001\n",
      ">0.001\n",
      ">0.009\n",
      ">0.004\n",
      ">0.004\n",
      ">0.004\n",
      ">0.005\n",
      ">0.011\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.005\n",
      ">0.003\n",
      ">0.004\n",
      ">0.003\n",
      ">0.005\n",
      ">0.004\n",
      ">0.004\n",
      ">0.003\n",
      ">0.004\n",
      ">0.004\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.005\n",
      ">0.003\n",
      ">0.003\n",
      ">0.004\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.004\n",
      ">0.004\n",
      ">0.003\n",
      ">0.004\n",
      ">0.003\n",
      "Unscaled_Inputs_Std_Output: 0.007 (0.004)\n",
      "Unscaled_inputs_Normalized_Output: 0.004 (0.000)\n",
      "Normalized_Inputs_Standardized_Output: 0.001 (0.000)\n",
      "Normalized_Inputs_Normalized_Output: 0.001 (0.002)\n",
      "Standardized_Inputs_Standardized_Output: 0.006 (0.003)\n",
      "Standardized_Inputs_Normalized_Output: 0.004 (0.001)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# compare scaling methods for mlp inputs on regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    " \n",
    "# prepare dataset with input and output scalers, can be none\n",
    "def get_dataset(input_scaler, output_scaler):\n",
    "\t# generate dataset\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "\t# split into train and test\n",
    "\tn_train = 500\n",
    "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "\ttrainy, testy = y[:n_train], y[n_train:]\n",
    "\t# scale inputs\n",
    "\tif input_scaler is not None:\n",
    "\t\t# fit scaler\n",
    "\t\tinput_scaler.fit(trainX)\n",
    "\t\t# transform training dataset\n",
    "\t\ttrainX = input_scaler.transform(trainX)\n",
    "\t\t# transform test dataset\n",
    "\t\ttestX = input_scaler.transform(testX)\n",
    "\tif output_scaler is not None:\n",
    "\t\t# reshape 1d arrays to 2d arrays\n",
    "\t\ttrainy = trainy.reshape(len(trainy), 1)\n",
    "\t\ttesty = testy.reshape(len(trainy), 1)\n",
    "\t\t# fit scaler on training dataset\n",
    "\t\toutput_scaler.fit(trainy)\n",
    "\t\t# transform training dataset\n",
    "\t\ttrainy = output_scaler.transform(trainy)\n",
    "\t\t# transform test dataset\n",
    "\t\ttesty = output_scaler.transform(testy)\n",
    "\treturn trainX, trainy, testX, testy\n",
    " \n",
    "# fit and evaluate mse of model on test set\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\t# evaluate the model\n",
    "\ttest_mse = model.evaluate(testX, testy, verbose=0)\n",
    "\treturn test_mse\n",
    " \n",
    "# evaluate model multiple times with given input and output scalers\n",
    "def repeated_evaluation(input_scaler, output_scaler, n_repeats=30):\n",
    "\t# get dataset\n",
    "\ttrainX, trainy, testX, testy = get_dataset(input_scaler, output_scaler)\n",
    "\t# repeated evaluation of model\n",
    "\tresults = list()\n",
    "\tfor _ in range(n_repeats):\n",
    "\t\ttest_mse = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tprint('>%.3f' % test_mse)\n",
    "\t\tresults.append(test_mse)\n",
    "\treturn results\n",
    " \n",
    "# unscaled inputs, standardized target\n",
    "results_unscaled_inputs_standardized_output = repeated_evaluation(None, StandardScaler())\n",
    "# unscaled inputs, normalized target\n",
    "results_unscaled_inputs_normalized_output = repeated_evaluation(None, MinMaxScaler())\n",
    "# normalized inputs, standardized target\n",
    "results_normalized_inputs_standardized_output = repeated_evaluation(MinMaxScaler(), StandardScaler())\n",
    "# normalized inputs, normalized target\n",
    "results_normalized_inputs_normalized_output = repeated_evaluation(MinMaxScaler(), MinMaxScaler())\n",
    "# standardized inputs, standardized target\n",
    "results_standardized_inputs_standardized_output = repeated_evaluation(StandardScaler(), StandardScaler())\n",
    "# standardized inputs, normalized target\n",
    "results_standardized_inputs_normalized_output = repeated_evaluation(StandardScaler(), MinMaxScaler())\n",
    "# summarize results\n",
    "print('Unscaled_Inputs_Std_Output: %.3f (%.3f)' % (mean(results_unscaled_inputs_standardized_output), std(results_unscaled_inputs_standardized_output)))\n",
    "print('Unscaled_inputs_Normalized_Output: %.3f (%.3f)' % (mean(results_unscaled_inputs_normalized_output), std(results_unscaled_inputs_normalized_output)))\n",
    "print('Normalized_Inputs_Standardized_Output: %.3f (%.3f)' % (mean(results_normalized_inputs_standardized_output), std(results_normalized_inputs_standardized_output)))\n",
    "print('Normalized_Inputs_Normalized_Output: %.3f (%.3f)' % (mean(results_normalized_inputs_normalized_output), std(results_normalized_inputs_normalized_output)))\n",
    "print('Standardized_Inputs_Standardized_Output: %.3f (%.3f)' % (mean(results_standardized_inputs_standardized_output), std(results_standardized_inputs_standardized_output)))\n",
    "print('Standardized_Inputs_Normalized_Output: %.3f (%.3f)' % (mean(results_standardized_inputs_normalized_output), std(results_standardized_inputs_normalized_output)))\n",
    "# plot results\n",
    "results = [results_unscaled_inputs_standardized_output, results_unscaled_inputs_normalized_output, results_normalized_inputs_standardized_output, results_normalized_inputs_normalized_output, results_standardized_inputs_standardized_output, results_standardized_inputs_normalized_output]\n",
    "labels = ['Unscaled IN Std OUT', 'Unscaled IN Norm OUT', 'Norm IN Std OUT', 'Norm IN Norm OUT', 'Std IN Std OUT', 'Std IN Norm OUT',]\n",
    "pyplot.boxplot(results, labels=labels)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da35bcd9",
   "metadata": {},
   "source": [
    "Scenarios 3 (Normalized_Inputs_Standardized_Output) and 4 (Normalized_Inputs_Normalized_Output) had the best and comparably same outcomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37b117",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "79662beb",
   "metadata": {},
   "source": [
    "# Other Scales. Update the example to evaluate other min/max scales when normalizing and compare performance, e.g. [-1, 1] and [0.0, 0.5]."
   ]
  },
  {
   "cell_type": "raw",
   "id": "f54cb77f",
   "metadata": {},
   "source": [
    "The default scale for the MinMaxScaler is to rescale variables into the range [0,1], although a preferred scale can be specified via the “feature_range” argument and specify a tuple including the min and the max for all variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf6d87fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.005\n",
      ">0.002\n",
      ">0.003\n",
      ">0.006\n",
      ">0.004\n",
      ">0.004\n",
      ">0.007\n",
      ">0.004\n",
      ">0.005\n",
      ">0.004\n",
      ">0.007\n",
      ">0.005\n",
      ">0.010\n",
      ">0.007\n",
      ">0.004\n",
      ">0.007\n",
      ">0.005\n",
      ">0.005\n",
      ">0.008\n",
      ">0.010\n",
      ">0.002\n",
      ">0.004\n",
      ">0.003\n",
      ">0.008\n",
      ">0.004\n",
      ">0.004\n",
      ">0.004\n",
      ">0.002\n",
      ">0.006\n",
      ">0.002\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.004\n",
      ">0.004\n",
      ">0.003\n",
      ">0.003\n",
      ">0.005\n",
      ">0.004\n",
      ">0.003\n",
      ">0.004\n",
      ">0.004\n",
      ">0.004\n",
      ">0.004\n",
      ">0.004\n",
      ">0.003\n",
      ">0.003\n",
      ">0.003\n",
      ">0.004\n",
      ">0.003\n",
      ">0.003\n",
      ">0.001\n",
      ">0.003\n",
      ">0.003\n",
      ">0.005\n",
      ">0.005\n",
      ">0.004\n",
      ">0.003\n",
      ">0.003\n",
      ">0.004\n",
      ">0.006\n",
      ">0.006\n",
      ">0.007\n",
      ">0.005\n",
      ">0.005\n",
      ">0.007\n",
      ">0.006\n",
      ">0.006\n",
      ">0.003\n",
      ">0.007\n",
      ">0.005\n",
      ">0.006\n",
      ">0.008\n",
      ">0.007\n",
      ">0.005\n",
      ">0.005\n",
      ">0.006\n",
      ">0.006\n",
      ">0.006\n",
      ">0.005\n",
      ">0.005\n",
      ">0.005\n",
      ">0.004\n",
      ">0.006\n",
      ">0.007\n",
      ">0.004\n",
      ">0.007\n",
      ">0.004\n",
      ">0.006\n",
      ">0.007\n",
      "Normalized_Inputs_Standardized_Output: 0.005 (0.002)\n",
      "Normalized_Inputs_Normalized_Output: 0.004 (0.001)\n",
      "Standardized_Inputs_Normalized_Output: 0.006 (0.001)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.001\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.001\n",
      ">0.000\n",
      ">0.000\n",
      ">0.002\n",
      ">0.001\n",
      ">0.005\n",
      ">0.000\n",
      ">0.000\n",
      ">0.000\n",
      ">0.001\n",
      ">0.003\n",
      ">0.006\n",
      ">0.001\n",
      ">0.002\n",
      ">0.002\n",
      ">0.002\n",
      ">0.001\n",
      ">0.001\n",
      ">0.002\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.002\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.001\n",
      ">0.002\n",
      ">0.001\n",
      ">0.002\n",
      ">0.002\n",
      ">0.003\n",
      ">0.002\n",
      ">0.001\n",
      ">0.002\n",
      ">0.001\n",
      ">0.002\n",
      ">0.002\n",
      ">0.001\n",
      ">0.002\n",
      ">0.001\n",
      ">0.002\n",
      ">0.002\n",
      ">0.002\n",
      ">0.002\n",
      ">0.001\n",
      ">0.002\n",
      ">0.002\n",
      ">0.001\n",
      ">0.002\n",
      ">0.002\n",
      ">0.002\n",
      ">0.002\n",
      ">0.001\n",
      ">0.002\n",
      ">0.002\n",
      "Normalized_Inputs_Standardized_Output: 0.000 (0.000)\n",
      "Normalized_Inputs_Normalized_Output: 0.001 (0.001)\n",
      "Standardized_Inputs_Normalized_Output: 0.002 (0.000)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# compare scaling methods for mlp inputs on regression problem\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from matplotlib import pyplot\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    " \n",
    "# prepare dataset with input and output scalers, can be none\n",
    "def get_dataset(input_scaler, output_scaler):\n",
    "\t# generate dataset\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, noise=0.1, random_state=1)\n",
    "\t# split into train and test\n",
    "\tn_train = 500\n",
    "\ttrainX, testX = X[:n_train, :], X[n_train:, :]\n",
    "\ttrainy, testy = y[:n_train], y[n_train:]\n",
    "\t# scale inputs\n",
    "\tif input_scaler is not None:\n",
    "\t\t# fit scaler\n",
    "\t\tinput_scaler.fit(trainX)\n",
    "\t\t# transform training dataset\n",
    "\t\ttrainX = input_scaler.transform(trainX)\n",
    "\t\t# transform test dataset\n",
    "\t\ttestX = input_scaler.transform(testX)\n",
    "\tif output_scaler is not None:\n",
    "\t\t# reshape 1d arrays to 2d arrays\n",
    "\t\ttrainy = trainy.reshape(len(trainy), 1)\n",
    "\t\ttesty = testy.reshape(len(trainy), 1)\n",
    "\t\t# fit scaler on training dataset\n",
    "\t\toutput_scaler.fit(trainy)\n",
    "\t\t# transform training dataset\n",
    "\t\ttrainy = output_scaler.transform(trainy)\n",
    "\t\t# transform test dataset\n",
    "\t\ttesty = output_scaler.transform(testy)\n",
    "\treturn trainX, trainy, testX, testy\n",
    " \n",
    "# fit and evaluate mse of model on test set\n",
    "def evaluate_model(trainX, trainy, testX, testy):\n",
    "\t# define model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(25, input_dim=20, activation='relu', kernel_initializer='he_uniform'))\n",
    "\tmodel.add(Dense(1, activation='linear'))\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='mean_squared_error', optimizer=SGD(learning_rate=0.01, momentum=0.9))\n",
    "\t# fit model\n",
    "\tmodel.fit(trainX, trainy, epochs=100, verbose=0)\n",
    "\t# evaluate the model\n",
    "\ttest_mse = model.evaluate(testX, testy, verbose=0)\n",
    "\treturn test_mse\n",
    " \n",
    "# evaluate model multiple times with given input and output scalers\n",
    "def repeated_evaluation(input_scaler, output_scaler, n_repeats=30):\n",
    "\t# get dataset\n",
    "\ttrainX, trainy, testX, testy = get_dataset(input_scaler, output_scaler)\n",
    "\t# repeated evaluation of model\n",
    "\tresults = list()\n",
    "\tfor _ in range(n_repeats):\n",
    "\t\ttest_mse = evaluate_model(trainX, trainy, testX, testy)\n",
    "\t\tprint('>%.3f' % test_mse)\n",
    "\t\tresults.append(test_mse)\n",
    "\treturn results\n",
    " \n",
    "\n",
    "# normalized inputs (feature_range=(-1,1)), standardized target\n",
    "results_normalized_inputs_standardized_output = repeated_evaluation(MinMaxScaler(feature_range=(-1,1)), StandardScaler())\n",
    "# normalized inputs(feature_range=(-1,1)), normalized target(feature_range=(-1,1))\n",
    "results_normalized_inputs_normalized_output = repeated_evaluation(MinMaxScaler(feature_range=(-1,1)), MinMaxScaler(feature_range=(-1,1)))\n",
    "# standardized inputs, normalized target(feature_range=(-1,1))\n",
    "results_standardized_inputs_normalized_output = repeated_evaluation(StandardScaler(), MinMaxScaler(feature_range=(-1,1)))\n",
    "# summarize results\n",
    "print('Normalized_Inputs_Standardized_Output: %.3f (%.3f)' % (mean(results_normalized_inputs_standardized_output), std(results_normalized_inputs_standardized_output)))\n",
    "print('Normalized_Inputs_Normalized_Output: %.3f (%.3f)' % (mean(results_normalized_inputs_normalized_output), std(results_normalized_inputs_normalized_output)))\n",
    "print('Standardized_Inputs_Normalized_Output: %.3f (%.3f)' % (mean(results_standardized_inputs_normalized_output), std(results_standardized_inputs_normalized_output)))\n",
    "# plot results\n",
    "results = [results_normalized_inputs_standardized_output, results_normalized_inputs_normalized_output, results_standardized_inputs_normalized_output]\n",
    "labels = ['Norm IN Std OUT', 'Norm IN Norm OUT', 'Std IN Norm OUT',]\n",
    "pyplot.boxplot(results, labels=labels)\n",
    "pyplot.show()\n",
    "\n",
    "\n",
    "\n",
    "# normalized inputs (feature_range=(0, 0.5)), standardized target\n",
    "results_normalized_inputs_standardized_output = repeated_evaluation(MinMaxScaler(feature_range=(0, 0.5)), StandardScaler())\n",
    "# normalized inputs(feature_range=(0, 0.5)), normalized target(feature_range=(0, 0.5))\n",
    "results_normalized_inputs_normalized_output = repeated_evaluation(MinMaxScaler(feature_range=(0, 0.5)), MinMaxScaler(feature_range=(0, 0.5)))\n",
    "# standardized inputs, normalized target(feature_range=(0, 0.5))\n",
    "results_standardized_inputs_normalized_output = repeated_evaluation(StandardScaler(), MinMaxScaler(feature_range=(0, 0.5)))\n",
    "# summarize results\n",
    "print('Normalized_Inputs_Standardized_Output: %.3f (%.3f)' % (mean(results_normalized_inputs_standardized_output), std(results_normalized_inputs_standardized_output)))\n",
    "print('Normalized_Inputs_Normalized_Output: %.3f (%.3f)' % (mean(results_normalized_inputs_normalized_output), std(results_normalized_inputs_normalized_output)))\n",
    "print('Standardized_Inputs_Normalized_Output: %.3f (%.3f)' % (mean(results_standardized_inputs_normalized_output), std(results_standardized_inputs_normalized_output)))\n",
    "# plot results\n",
    "results = [results_normalized_inputs_standardized_output, results_normalized_inputs_normalized_output, results_standardized_inputs_normalized_output]\n",
    "labels = ['Norm IN Std OUT', 'Norm IN Norm OUT', 'Std IN Norm OUT',]\n",
    "pyplot.boxplot(results, labels=labels)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "625d7564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Intersting; a model trained with normalized inputs (feature_range=(0, 0.5)) and standardized target lead to best model \n",
    "# that had nearly zero training and test loses. It appears to be a slightly better predictive model than a model trained with \n",
    "# normalized inputs(feature_range=(0, 1)) and standardized target.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fa47c21a",
   "metadata": {},
   "source": [
    "Summary\n",
    "In this tutorial, you discovered how to improve neural network stability and modeling performance by scaling data.\n",
    "\n",
    "Specifically, you learned:\n",
    "\n",
    "Data scaling is a recommended pre-processing step when working with deep learning neural networks.\n",
    "Data scaling can be achieved by normalizing or standardizing real-valued input and output variables.\n",
    "How to apply standardization and normalization to improve the performance of a Multilayer Perceptron model on a regression predictive modeling problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cccf4a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
