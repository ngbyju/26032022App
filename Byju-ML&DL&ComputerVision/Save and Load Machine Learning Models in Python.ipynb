{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ab948f21",
   "metadata": {},
   "source": [
    "# Save and Load Machine Learning Models in Python with scikit-learn\n",
    "https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe20743c",
   "metadata": {},
   "source": [
    "Finding an accurate machine learning model is not the end of the project.\n",
    "\n",
    "In this post you will discover how to save and load your machine learning model in Python using scikit-learn.\n",
    "\n",
    "This allows you to save your model to file and load it later in order to make predictions.\n",
    "\n",
    "\n",
    "Update Jan/2017: Updated to reflect changes to the scikit-learn API in version 0.18.\n",
    "Update Mar/2018: Added alternate link to download the dataset as the original appears to have been taken down.\n",
    "Update Oct/2019: Fixed typo in comment.\n",
    "Update Feb/2020: Updated joblib API.\n",
    "Save and Load Machine Learning Models in Python with scikit-learn\n",
    "Save and Load Machine Learning Models in Python with scikit-learn\n",
    "\n",
    "\n",
    "Tutorial Overview\n",
    "This tutorial is divided into 3 parts, they are:\n",
    "\n",
    "Save Your Model with pickle\n",
    "Save Your Model with joblib\n",
    "Tips for Saving Your Model\n",
    "\n",
    "Save Your Model with pickle\n",
    "Pickle is the standard way of serializing objects in Python.\n",
    "\n",
    "You can use the pickle operation to serialize your machine learning algorithms and save the serialized format to a file.\n",
    "\n",
    "Later you can load this file to deserialize your model and use it to make new predictions.\n",
    "\n",
    "The example below demonstrates how you can train a logistic regression model on the Pima Indians onset of diabetes dataset, save the model to file and load it to make predictions on the unseen test set (download from here).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cded25",
   "metadata": {},
   "source": [
    "# Save Model Using Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90d56bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874015748031497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Byju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save Model Using Pickle\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import pickle\n",
    "#url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv('pima-indians-diabetes.csv', delimiter=',', names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# Fit the model on training set\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = pickle.load(open(filename, 'rb'))\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "819f4f24",
   "metadata": {},
   "source": [
    "\n",
    "Running the example saves the model to finalized_model.sav in your local working directory.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "Load the saved model and evaluating it provides an estimate of accuracy of the model on unseen data.\n",
    "\n",
    "0.7874015748031497\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "974a3d4c",
   "metadata": {},
   "source": [
    "# Save Your Model with joblib"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9b92241e",
   "metadata": {},
   "source": [
    "\n",
    "Joblib is part of the SciPy ecosystem and provides utilities for pipelining Python jobs.\n",
    "\n",
    "It provides utilities for saving and loading Python objects that make use of NumPy data structures, efficiently.\n",
    "\n",
    "This can be useful for some machine learning algorithms that require a lot of parameters or store the entire dataset (like K-Nearest Neighbors).\n",
    "\n",
    "The example below demonstrates how you can train a logistic regression model on the Pima Indians onset of diabetes dataset, saves the model to file using joblib and load it to make predictions on the unseen test set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6efc947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7874015748031497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Byju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Save Model Using joblib\n",
    "import pandas\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "#url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/pima-indians-diabetes.data.csv\"\n",
    "names = ['preg', 'plas', 'pres', 'skin', 'test', 'mass', 'pedi', 'age', 'class']\n",
    "dataframe = pandas.read_csv('pima-indians-diabetes.csv', delimiter=',', names=names)\n",
    "array = dataframe.values\n",
    "X = array[:,0:8]\n",
    "Y = array[:,8]\n",
    "test_size = 0.33\n",
    "seed = 7\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "# Fit the model on training set\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "# save the model to disk\n",
    "filename = 'finalized_model.sav'\n",
    "joblib.dump(model, filename)\n",
    " \n",
    "# some time later...\n",
    " \n",
    "# load the model from disk\n",
    "loaded_model = joblib.load(filename)\n",
    "result = loaded_model.score(X_test, Y_test)\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e1eb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "Running the example saves the model to file as finalized_model.sav and also creates one file for each NumPy array in the model (four additional files).\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "After the model is loaded an estimate of the accuracy of the model on unseen data is reported.\n",
    "\n",
    "0.7874015748031497\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eb33038",
   "metadata": {},
   "source": [
    "# Tips for Saving Your Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a859f391",
   "metadata": {},
   "source": [
    "\n",
    "This section lists some important considerations when finalizing your machine learning models.\n",
    "\n",
    "Python Version. Take note of the python version. You almost certainly require the same major (and maybe minor) version of Python used to serialize the model when you later load it and deserialize it.\n",
    "Library Versions. The version of all major libraries used in your machine learning project almost certainly need to be the same when deserializing a saved model. This is not limited to the version of NumPy and the version of scikit-learn.\n",
    "Manual Serialization. You might like to manually output the parameters of your learned model so that you can use them directly in scikit-learn or another platform in the future. Often the algorithms used by machine learning algorithms to make predictions are a lot simpler than those used to learn the parameters can may be easy to implement in custom code that you have control over.\n",
    "Take note of the version so that you can re-create the environment if for some reason you cannot reload your model on another machine or another platform at a later time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a1839d",
   "metadata": {},
   "source": [
    "# Summary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a75f4bb4",
   "metadata": {},
   "source": [
    "\n",
    "In this post you discovered how to persist your machine learning algorithms in Python with scikit-learn.\n",
    "\n",
    "You learned two techniques that you can use:\n",
    "\n",
    "The pickle API for serializing standard Python objects.\n",
    "The joblib API for efficiently serializing Python objects with NumPy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a1b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a04d7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
