{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7dee242",
   "metadata": {},
   "source": [
    "# Stacking Ensemble Machine Learning With Python\n",
    "https://machinelearningmastery.com/stacking-ensemble-machine-learning-with-python/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7235cc0b",
   "metadata": {},
   "source": [
    "Stacking or Stacked Generalization is an ensemble machine learning algorithm.\n",
    "\n",
    "It uses a meta-learning algorithm to learn how to best combine the predictions from two or more base machine learning algorithms.\n",
    "\n",
    "The benefit of stacking is that it can harness the capabilities of a range of well-performing models on a classification or regression task and make predictions that have better performance than any single model in the ensemble.\n",
    "\n",
    "In this tutorial, you will discover the stacked generalization ensemble or stacking in Python.\n",
    "\n",
    "After completing this tutorial, you will know:\n",
    "\n",
    "Stacking is an ensemble machine learning algorithm that learns how to best combine the predictions from multiple well-performing machine learning models.\n",
    "The scikit-learn library provides a standard implementation of the stacking ensemble in Python.\n",
    "How to use stacking ensembles for regression and classification predictive modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd6eb05",
   "metadata": {},
   "source": [
    "# Tutorial Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dba7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "This tutorial is divided into four parts; they are:\n",
    "\n",
    "1. Stacked Generalization\n",
    "2. Stacking Scikit-Learn API\n",
    "3. Stacking for Classification\n",
    "4. Stacking for Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d123775",
   "metadata": {},
   "source": [
    "# Stacked Generalization"
   ]
  },
  {
   "cell_type": "raw",
   "id": "946b6536",
   "metadata": {},
   "source": [
    "\n",
    "Stacked Generalization or “Stacking” for short is an ensemble machine learning algorithm.\n",
    "\n",
    "It involves combining the predictions from multiple machine learning models on the same dataset, like bagging and boosting.\n",
    "\n",
    "Stacking addresses the question:\n",
    "\n",
    "Given multiple machine learning models that are skillful on a problem, but in different ways, how do you choose which model to use (trust)?\n",
    "The approach to this question is to use another machine learning model that learns when to use or trust each model in the ensemble.\n",
    "\n",
    "Unlike bagging, in stacking, the models are typically different (e.g. not all decision trees) and fit on the same dataset (e.g. instead of samples of the training dataset).\n",
    "Unlike boosting, in stacking, a single model is used to learn how to best combine the predictions from the contributing models (e.g. instead of a sequence of models that correct the predictions of prior models).\n",
    "The architecture of a stacking model involves two or more base models, often referred to as level-0 models, and a meta-model that combines the predictions of the base models, referred to as a level-1 model.\n",
    "\n",
    "Level-0 Models (Base-Models): Models fit on the training data and whose predictions are compiled.\n",
    "Level-1 Model (Meta-Model): Model that learns how to best combine the predictions of the base models.\n",
    "The meta-model is trained on the predictions made by base models on out-of-sample data. That is, data not used to train the base models is fed to the base models, predictions are made, and these predictions, along with the expected outputs, provide the input and output pairs of the training dataset used to fit the meta-model.\n",
    "\n",
    "The outputs from the base models used as input to the meta-model may be real value in the case of regression, and probability values, probability like values, or class labels in the case of classification.\n",
    "\n",
    "The most common approach to preparing the training dataset for the meta-model is via k-fold cross-validation of the base models, where the out-of-fold predictions are used as the basis for the training dataset for the meta-model.\n",
    "\n",
    "The training data for the meta-model may also include the inputs to the base models, e.g. input elements of the training data. This can provide an additional context to the meta-model as to how to best combine the predictions from the meta-model.\n",
    "\n",
    "Once the training dataset is prepared for the meta-model, the meta-model can be trained in isolation on this dataset, and the base-models can be trained on the entire original training dataset.\n",
    "\n",
    "Stacking is appropriate when multiple different machine learning models have skill on a dataset, but have skill in different ways. Another way to say this is that the predictions made by the models or the errors in predictions made by the models are uncorrelated or have a low correlation.\n",
    "\n",
    "Base-models are often complex and diverse. As such, it is often a good idea to use a range of models that make very different assumptions about how to solve the predictive modeling task, such as linear models, decision trees, support vector machines, neural networks, and more. Other ensemble algorithms may also be used as base-models, such as random forests.\n",
    "\n",
    "Base-Models: Use a diverse range of models that make different assumptions about the prediction task.\n",
    "The meta-model is often simple, providing a smooth interpretation of the predictions made by the base models. As such, linear models are often used as the meta-model, such as linear regression for regression tasks (predicting a numeric value) and logistic regression for classification tasks (predicting a class label). Although this is common, it is not required.\n",
    "\n",
    "Regression Meta-Model: Linear Regression.\n",
    "Classification Meta-Model: Logistic Regression.\n",
    "The use of a simple linear model as the meta-model often gives stacking the colloquial name “blending.” As in the prediction is a weighted average or blending of the predictions made by the base models.\n",
    "\n",
    "The super learner may be considered a specialized type of stacking.\n",
    "\n",
    "Stacking is designed to improve modeling performance, although is not guaranteed to result in an improvement in all cases.\n",
    "\n",
    "Achieving an improvement in performance depends on the complexity of the problem and whether it is sufficiently well represented by the training data and complex enough that there is more to learn by combining predictions. It is also dependent upon the choice of base models and whether they are sufficiently skillful and sufficiently uncorrelated in their predictions (or errors).\n",
    "\n",
    "If a base-model performs as well as or better than the stacking ensemble, the base model should be used instead, given its lower complexity (e.g. it’s simpler to describe, train and maintain).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc0208b",
   "metadata": {},
   "source": [
    "# Stacking Scikit-Learn API"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ade63bbc",
   "metadata": {},
   "source": [
    "\n",
    "Stacking can be implemented from scratch, although this can be challenging for beginners.\n",
    "\n",
    "For an example of implementing stacking from scratch in Python, see the tutorial:\n",
    "\n",
    "How to Implement Stacked Generalization (Stacking) From Scratch With Python\n",
    "For an example of implementing stacking from scratch for deep learning, see the tutorial:\n",
    "\n",
    "How to Develop a Stacking Ensemble for Deep Learning Neural Networks in Python\n",
    "The scikit-learn Python machine learning library provides an implementation of stacking for machine learning.\n",
    "\n",
    "It is available in version 0.22 of the library and higher.\n",
    "\n",
    "First, confirm that you are using a modern version of the library by running the following script:\n",
    "\n",
    "# check scikit-learn version\n",
    "import sklearn\n",
    "print(sklearn.__version__)\n",
    "Running the script will print your version of scikit-learn.\n",
    "\n",
    "Your version should be the same or higher. If not, you must upgrade your version of the scikit-learn library.\n",
    "\n",
    "0.22.1\n",
    "Stacking is provided via the StackingRegressor and StackingClassifier classes.\n",
    "\n",
    "Both models operate the same way and take the same arguments. Using the model requires that you specify a list of estimators (level-0 models), and a final estimator (level-1 or meta-model).\n",
    "\n",
    "A list of level-0 models or base models is provided via the “estimators” argument. This is a Python list where each element in the list is a tuple with the name of the model and the configured model instance.\n",
    "\n",
    "For example, below defines two level-0 models:\n",
    "\n",
    "...\n",
    "models = [('lr',LogisticRegression()),('svm',SVC())\n",
    "stacking = StackingClassifier(estimators=models)\n",
    "Each model in the list may also be a Pipeline, including any data preparation required by the model prior to fitting the model on the training dataset. For example:\n",
    "\n",
    "...\n",
    "models = [('lr',LogisticRegression()),('svm',make_pipeline(StandardScaler(),SVC()))\n",
    "stacking = StackingClassifier(estimators=models)\n",
    "The level-1 model or meta-model is provided via the “final_estimator” argument. By default, this is set to LinearRegression for regression and LogisticRegression for classification, and these are sensible defaults that you probably do not want to change.\n",
    "\n",
    "The dataset for the meta-model is prepared using cross-validation. By default, 5-fold cross-validation is used, although this can be changed via the “cv” argument and set to either a number (e.g. 10 for 10-fold cross-validation) or a cross-validation object (e.g. StratifiedKFold).\n",
    "\n",
    "Sometimes, better performance can be achieved if the dataset prepared for the meta-model also includes inputs to the level-0 models, e.g. the input training data. This can be achieved by setting the “passthrough” argument to True and is not enabled by default.\n",
    "\n",
    "Now that we are familiar with the stacking API in scikit-learn, let’s look at some worked examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1fb7d0",
   "metadata": {},
   "source": [
    "# Stacking for Classification"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0117b896",
   "metadata": {},
   "source": [
    "In this section, we will look at using stacking for a classification problem.\n",
    "\n",
    "First, we can use the make_classification() function to create a synthetic binary classification problem with 1,000 examples and 20 input features.\n",
    "\n",
    "The complete example is listed below.\n",
    "\n",
    "# test classification dataset\n",
    "from sklearn.datasets import make_classification\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)\n",
    "Running the example creates the dataset and summarizes the shape of the input and output components.\n",
    "\n",
    "(1000, 20) (1000,)\n",
    "Next, we can evaluate a suite of different machine learning models on the dataset.\n",
    "\n",
    "Specifically, we will evaluate the following five algorithms:\n",
    "\n",
    "Logistic Regression.\n",
    "k-Nearest Neighbors.\n",
    "Decision Tree.\n",
    "Support Vector Machine.\n",
    "Naive Bayes.\n",
    "Each algorithm will be evaluated using default model hyperparameters. The function get_models() below creates the models we wish to evaluate.\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['lr'] = LogisticRegression()\n",
    "\tmodels['knn'] = KNeighborsClassifier()\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['svm'] = SVC()\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\treturn models\n",
    "Each model will be evaluated using repeated k-fold cross-validation.\n",
    "\n",
    "The evaluate_model() function below takes a model instance and returns a list of scores from three repeats of stratified 10-fold cross-validation.\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "We can then report the mean performance of each algorithm and also create a box and whisker plot to compare the distribution of accuracy scores for each algorithm.\n",
    "\n",
    "Tying this together, the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ce2b625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.866 (0.029)\n",
      ">knn 0.931 (0.025)\n",
      ">cart 0.822 (0.044)\n",
      ">svm 0.957 (0.020)\n",
      ">bayes 0.833 (0.031)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compare standalone models for binary classification\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "\treturn X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['lr'] = LogisticRegression()\n",
    "\tmodels['knn'] = KNeighborsClassifier()\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['svm'] = SVC()\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "43fb6107",
   "metadata": {},
   "source": [
    "Running the example first reports the mean and standard deviation accuracy for each model.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "We can see that in this case, SVM performs the best with about 95.7 percent mean accuracy.\n",
    "\n",
    ">lr 0.866 (0.029)\n",
    ">knn 0.931 (0.025)\n",
    ">cart 0.821 (0.050)\n",
    ">svm 0.957 (0.020)\n",
    ">bayes 0.833 (0.031)\n",
    "A box-and-whisker plot is then created comparing the distribution accuracy scores for each model, allowing us to clearly see that KNN and SVM perform better on average than LR, CART, and Bayes."
   ]
  },
  {
   "cell_type": "raw",
   "id": "cbff1943",
   "metadata": {},
   "source": [
    "Here we have five different algorithms that perform well, presumably in different ways on this dataset.\n",
    "\n",
    "Next, we can try to combine these five models into a single ensemble model using stacking.\n",
    "\n",
    "We can use a logistic regression model to learn how to best combine the predictions from each of the separate five models.\n",
    "\n",
    "The get_stacking() function below defines the StackingClassifier model by first defining a list of tuples for the five base models, then defining the logistic regression meta-model to combine the predictions from the base models using 5-fold cross-validation.\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('lr', LogisticRegression()))\n",
    "\tlevel0.append(('knn', KNeighborsClassifier()))\n",
    "\tlevel0.append(('cart', DecisionTreeClassifier()))\n",
    "\tlevel0.append(('svm', SVC()))\n",
    "\tlevel0.append(('bayes', GaussianNB()))\n",
    "\t# define meta learner model\n",
    "\tlevel1 = LogisticRegression()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    "We can include the stacking ensemble in the list of models to evaluate, along with the standalone models.\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['lr'] = LogisticRegression()\n",
    "\tmodels['knn'] = KNeighborsClassifier()\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['svm'] = SVC()\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\treturn models\n",
    "Our expectation is that the stacking ensemble will perform better than any single base model.\n",
    "\n",
    "This is not always the case and if it is not the case, then the base model should be used in favor of the ensemble model.\n",
    "\n",
    "The complete example of evaluating the stacking ensemble model alongside the standalone models is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "35086f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">lr 0.866 (0.029)\n",
      ">knn 0.931 (0.025)\n",
      ">cart 0.823 (0.042)\n",
      ">svm 0.957 (0.020)\n",
      ">bayes 0.833 (0.031)\n",
      ">stacking 0.964 (0.019)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# compare ensemble to each baseline classifier\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "\treturn X, y\n",
    " \n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('lr', LogisticRegression()))\n",
    "\tlevel0.append(('knn', KNeighborsClassifier()))\n",
    "\tlevel0.append(('cart', DecisionTreeClassifier()))\n",
    "\tlevel0.append(('svm', SVC()))\n",
    "\tlevel0.append(('bayes', GaussianNB()))\n",
    "\t# define meta learner model\n",
    "\tlevel1 = LogisticRegression()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['lr'] = LogisticRegression()\n",
    "\tmodels['knn'] = KNeighborsClassifier()\n",
    "\tmodels['cart'] = DecisionTreeClassifier()\n",
    "\tmodels['svm'] = SVC()\n",
    "\tmodels['bayes'] = GaussianNB()\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\treturn models\n",
    " \n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bf8a2fcc",
   "metadata": {},
   "source": [
    "Running the example first reports the performance of each model. This includes the performance of each base model, then the stacking ensemble.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "In this case, we can see that the stacking ensemble appears to perform better than any single model on average, achieving an accuracy of about 96.4 percent.\n",
    "\n",
    ">lr 0.866 (0.029)\n",
    ">knn 0.931 (0.025)\n",
    ">cart 0.820 (0.044)\n",
    ">svm 0.957 (0.020)\n",
    ">bayes 0.833 (0.031)\n",
    ">stacking 0.964 (0.019)\n",
    "A box plot is created showing the distribution of model classification accuracies.\n",
    "\n",
    "Here, we can see that the mean and median accuracy for the stacking model sits slightly higher than the SVM model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e07178b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 0\n"
     ]
    }
   ],
   "source": [
    "# make a prediction with a stacking ensemble\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "# define dataset\n",
    "X, y = make_classification(n_samples=1000, n_features=20, n_informative=15, n_redundant=5, random_state=1)\n",
    "# define the base models\n",
    "level0 = list()\n",
    "level0.append(('lr', LogisticRegression()))\n",
    "level0.append(('knn', KNeighborsClassifier()))\n",
    "level0.append(('cart', DecisionTreeClassifier()))\n",
    "level0.append(('svm', SVC()))\n",
    "level0.append(('bayes', GaussianNB()))\n",
    "# define meta learner model\n",
    "level1 = LogisticRegression()\n",
    "# define the stacking ensemble\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "# fit the model on all available data\n",
    "model.fit(X, y)\n",
    "# make a prediction for one example\n",
    "data = [[2.47475454,0.40165523,1.68081787,2.88940715,0.91704519,-3.07950644,4.39961206,0.72464273,-4.86563631,-6.06338084,-1.22209949,-0.4699618,1.01222748,-0.6899355,-0.53000581,6.86966784,-3.27211075,-6.59044146,-2.21290585,-3.139579]]\n",
    "yhat = model.predict(data)\n",
    "print('Predicted Class: %d' % (yhat))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2065b046",
   "metadata": {},
   "source": [
    "Running the example fits the stacking ensemble model on the entire dataset and is then used to make a prediction on a new row of data, as we might when using the model in an application."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b95f6436",
   "metadata": {},
   "source": [
    "# Stacking for Regression"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4fe0a85b",
   "metadata": {},
   "source": [
    "In this section, we will look at using stacking for a regression problem.\n",
    "\n",
    "First, we can use the make_regression() function to create a synthetic regression problem with 1,000 examples and 20 input features.\n",
    "\n",
    "The complete example is listed below.\n",
    "\n",
    "# test regression dataset\n",
    "from sklearn.datasets import make_regression\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "# summarize the dataset\n",
    "print(X.shape, y.shape)\n",
    "Running the example creates the dataset and summarizes the shape of the input and output components.\n",
    "\n",
    "(1000, 20) (1000,)\n",
    "Next, we can evaluate a suite of different machine learning models on the dataset.\n",
    "\n",
    "Specifically, we will evaluate the following three algorithms:\n",
    "\n",
    "k-Nearest Neighbors.\n",
    "Decision Tree.\n",
    "Support Vector Regression.\n",
    "Note: The test dataset can be trivially solved using a linear regression model as the dataset was created using a linear model under the covers. As such, we will leave this model out of the example so we can demonstrate the benefit of the stacking ensemble method.\n",
    "\n",
    "Each algorithm will be evaluated using the default model hyperparameters. The function get_models() below creates the models we wish to evaluate.\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['knn'] = KNeighborsRegressor()\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['svm'] = SVR()\n",
    "\treturn models\n",
    "Each model will be evaluated using repeated k-fold cross-validation. The evaluate_model() function below takes a model instance and returns a list of scores from three repeats of 10-fold cross-validation.\n",
    "\n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    "We can then report the mean performance of each algorithm and also create a box and whisker plot to compare the distribution of accuracy scores for each algorithm.\n",
    "\n",
    "In this case, model performance will be reported using the mean absolute error (MAE). The scikit-learn library inverts the sign on this error to make it maximizing, from -infinity to 0 for the best score.\n",
    "\n",
    "Tying this together, the complete example is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50d3949d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">knn -101.019 (7.161)\n",
      ">cart -148.730 (11.137)\n",
      ">svm -162.419 (12.565)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# compare machine learning models for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "\treturn X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['knn'] = KNeighborsRegressor()\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['svm'] = SVR()\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1c3d169b",
   "metadata": {},
   "source": [
    "Running the example first reports the mean and standard deviation MAE for each model.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "We can see that in this case, KNN performs the best with a mean negative MAE of about -100.\n",
    "\n",
    ">knn -101.019 (7.161)\n",
    ">cart -148.100 (11.039)\n",
    ">svm -162.419 (12.565)\n",
    "A box-and-whisker plot is then created comparing the distribution negative MAE scores for each model."
   ]
  },
  {
   "cell_type": "raw",
   "id": "e0053066",
   "metadata": {},
   "source": [
    "Here we have three different algorithms that perform well, presumably in different ways on this dataset.\n",
    "\n",
    "Next, we can try to combine these three models into a single ensemble model using stacking.\n",
    "\n",
    "We can use a linear regression model to learn how to best combine the predictions from each of the separate three models.\n",
    "\n",
    "The get_stacking() function below defines the StackingRegressor model by first defining a list of tuples for the three base models, then defining the linear regression meta-model to combine the predictions from the base models using 5-fold cross-validation.\n",
    "\n",
    "\n",
    "\n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('knn', KNeighborsRegressor()))\n",
    "\tlevel0.append(('cart', DecisionTreeRegressor()))\n",
    "\tlevel0.append(('svm', SVR()))\n",
    "\t# define meta learner model\n",
    "\tlevel1 = LinearRegression()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    "We can include the stacking ensemble in the list of models to evaluate, along with the standalone models.\n",
    "\n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['knn'] = KNeighborsRegressor()\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['svm'] = SVR()\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\treturn models\n",
    "Our expectation is that the stacking ensemble will perform better than any single base model.\n",
    "\n",
    "This is not always the case, and if it is not the case, then the base model should be used in favor of the ensemble model.\n",
    "\n",
    "The complete example of evaluating the stacking ensemble model alongside the standalone models is listed below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9588dd95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">knn -101.019 (7.161)\n",
      ">cart -148.821 (11.145)\n",
      ">svm -162.419 (12.565)\n",
      ">stacking -56.738 (5.337)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# compare ensemble to each standalone models for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "\treturn X, y\n",
    " \n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tlevel0.append(('knn', KNeighborsRegressor()))\n",
    "\tlevel0.append(('cart', DecisionTreeRegressor()))\n",
    "\tlevel0.append(('svm', SVR()))\n",
    "\t# define meta learner model\n",
    "\tlevel1 = LinearRegression()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['knn'] = KNeighborsRegressor()\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['svm'] = SVR()\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "bb91000e",
   "metadata": {},
   "source": [
    "Running the example first reports the performance of each model. This includes the performance of each base model, then the stacking ensemble.\n",
    "\n",
    "Note: Your results may vary given the stochastic nature of the algorithm or evaluation procedure, or differences in numerical precision. Consider running the example a few times and compare the average outcome.\n",
    "\n",
    "In this case, we can see that the stacking ensemble appears to perform better than any single model on average, achieving a mean negative MAE of about -56.\n",
    "\n",
    ">knn -101.019 (7.161)\n",
    ">cart -148.821 (11.145)\n",
    ">svm -162.419 (12.565)\n",
    ">stacking -56.738 (5.337)\n",
    "\n",
    "A box plot is created showing the distribution of model error scores. Here, we can see that the mean and median scores for the stacking model sit much higher than any individual model.\n",
    "\n",
    "If we choose a stacking ensemble as our final model, we can fit and use it to make predictions on new data just like any other model.\n",
    "\n",
    "First, the stacking ensemble is fit on all available data, then the predict() function can be called to make predictions on new data.\n",
    "\n",
    "The example below demonstrates this on our regression dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63d06ed0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: 557.938\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make a prediction with a stacking ensemble\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "# define the base models\n",
    "level0 = list()\n",
    "level0.append(('knn', KNeighborsRegressor()))\n",
    "level0.append(('cart', DecisionTreeRegressor()))\n",
    "level0.append(('svm', SVR()))\n",
    "# define meta learner model\n",
    "level1 = LinearRegression()\n",
    "# define the stacking ensemble\n",
    "model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "# fit the model on all available data\n",
    "model.fit(X, y)\n",
    "# make a prediction for one example\n",
    "data = [[0.59332206,-0.56637507,1.34808718,-0.57054047,-0.72480487,1.05648449,0.77744852,0.07361796,0.88398267,2.02843157,1.01902732,0.11227799,0.94218853,0.26741783,0.91458143,-0.72759572,1.08842814,-0.61450942,-0.69387293,1.69169009]]\n",
    "yhat = model.predict(data)\n",
    "print('Predicted Value: %.3f' % (yhat))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8d2a1cb8",
   "metadata": {},
   "source": [
    "Running the example fits the stacking ensemble model on the entire dataset and is then used to make a prediction on a new row of data, as we might when using the model in an application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1657956",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ededdf3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b486cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9313ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae071a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "77eecaa9",
   "metadata": {},
   "source": [
    "# See what happens when a linear regression model was included as base-model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e75b5c43",
   "metadata": {},
   "source": [
    "Out of curiosity, I (Byju) did incorporare a linear regression model into the base estimator and it appears that the base linear regression model had the lowest error among all base models and it was (linear regression base-model) performed much better than the stacking ensemble. Hnece the linear regression base model should could be used instead, given its lower complexity (e.g. it’s simpler to describe, train and maintain)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03aad3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">linr -0.083 (0.006)\n",
      ">knn -101.019 (7.161)\n",
      ">cart -149.263 (11.352)\n",
      ">svm -162.419 (12.565)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# compare machine learning models for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "\treturn X, y\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['linr'] = LinearRegression()\n",
    "\tmodels['knn'] = KNeighborsRegressor()\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['svm'] = SVR()\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b8a0f90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">linr -0.083 (0.006)\n",
      ">knn -101.019 (7.161)\n",
      ">cart -148.202 (11.629)\n",
      ">svm -162.419 (12.565)\n",
      ">stacking -56.773 (5.195)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# compare ensemble to each standalone models for regression\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "from matplotlib import pyplot\n",
    " \n",
    "# get the dataset\n",
    "def get_dataset():\n",
    "\tX, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "\treturn X, y\n",
    " \n",
    "# get a stacking ensemble of models\n",
    "def get_stacking():\n",
    "\t# define the base models\n",
    "\tlevel0 = list()\n",
    "\tmodels['linr'] = LinearRegression()\n",
    "\tlevel0.append(('knn', KNeighborsRegressor()))\n",
    "\tlevel0.append(('cart', DecisionTreeRegressor()))\n",
    "\tlevel0.append(('svm', SVR()))\n",
    "\t# define meta learner model\n",
    "\tlevel1 = LinearRegression()\n",
    "\t# define the stacking ensemble\n",
    "\tmodel = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "\treturn model\n",
    " \n",
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tmodels['linr'] = LinearRegression()\n",
    "\tmodels['knn'] = KNeighborsRegressor()\n",
    "\tmodels['cart'] = DecisionTreeRegressor()\n",
    "\tmodels['svm'] = SVR()\n",
    "\tmodels['stacking'] = get_stacking()\n",
    "\treturn models\n",
    " \n",
    "# evaluate a given model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\tcv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\tscores = cross_val_score(model, X, y, scoring='neg_mean_absolute_error', cv=cv, n_jobs=-1, error_score='raise')\n",
    "\treturn scores\n",
    " \n",
    "# define dataset\n",
    "X, y = get_dataset()\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97bfdb16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Value: 419.556\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# make a prediction with a stacking ensemble\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import StackingRegressor\n",
    "# define dataset\n",
    "X, y = make_regression(n_samples=1000, n_features=20, n_informative=15, noise=0.1, random_state=1)\n",
    "# define the base models\n",
    "level0 = list()\n",
    "model = LinearRegression()\n",
    "# define meta learner model\n",
    "#level1 = LinearRegression()\n",
    "# define the stacking ensemble\n",
    "#model = models['linr'] # StackingRegressor(estimators=level0, final_estimator=level1, cv=5)\n",
    "# fit the model on all available data\n",
    "model.fit(X, y)\n",
    "# make a prediction for one example\n",
    "data = [[0.59332206,-0.56637507,1.34808718,-0.57054047,-0.72480487,1.05648449,0.77744852,0.07361796,0.88398267,2.02843157,1.01902732,0.11227799,0.94218853,0.26741783,0.91458143,-0.72759572,1.08842814,-0.61450942,-0.69387293,1.69169009]]\n",
    "yhat = model.predict(data)\n",
    "print('Predicted Value: %.3f' % (yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb044fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
