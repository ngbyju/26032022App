{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d4ad55a",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbourhood Classsification\n",
    "Byju N Govindan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1bf0be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import operator\n",
    "\n",
    "from sklearn.model_selection import train_test_split , KFold\n",
    "from sklearn.preprocessing import Normalizer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV # Hyperparamter tuning\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import recall_score , precision_score , roc_auc_score ,roc_curve\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #to remove unwanted warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e815e02f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   target  \n",
       "0     0.0  \n",
       "1     0.0  \n",
       "2     0.0  \n",
       "3     0.0  \n",
       "4     0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iris dataset\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# import iris dataset\n",
    "iris = load_iris()\n",
    "# np.c_ is the numpy concatenate function\n",
    "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']],\n",
    "                      columns= iris['feature_names'] + ['target'])\n",
    "iris_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145d752d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.057333</td>\n",
       "      <td>3.758000</td>\n",
       "      <td>1.199333</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.435866</td>\n",
       "      <td>1.765298</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.819232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal length (cm)  sepal width (cm)  petal length (cm)  \\\n",
       "count         150.000000        150.000000         150.000000   \n",
       "mean            5.843333          3.057333           3.758000   \n",
       "std             0.828066          0.435866           1.765298   \n",
       "min             4.300000          2.000000           1.000000   \n",
       "25%             5.100000          2.800000           1.600000   \n",
       "50%             5.800000          3.000000           4.350000   \n",
       "75%             6.400000          3.300000           5.100000   \n",
       "max             7.900000          4.400000           6.900000   \n",
       "\n",
       "       petal width (cm)      target  \n",
       "count        150.000000  150.000000  \n",
       "mean           1.199333    1.000000  \n",
       "std            0.762238    0.819232  \n",
       "min            0.100000    0.000000  \n",
       "25%            0.300000    0.000000  \n",
       "50%            1.300000    1.000000  \n",
       "75%            1.800000    2.000000  \n",
       "max            2.500000    2.000000  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Describe the dataset\n",
    "iris_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7307e18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into X and Y\n",
    "#X= iris_df.iloc[:, :-1] # Extract all rows in all but last column in the df\n",
    "#y= iris_df.iloc[:, -1]  # Extract all rows in last column in the df\n",
    "\n",
    "X=iris_df.iloc[1:,:3]#features  # Extract all rows in all but last column in the df\n",
    "y=iris_df.iloc[1:,4:]#class labels # Extract all rows in last column in the df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "205d717f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   sepal length (cm)  sepal width (cm)  petal length (cm)\n",
      "1                4.9               3.0                1.4\n",
      "2                4.7               3.2                1.3\n",
      "3                4.6               3.1                1.5\n",
      "4                5.0               3.6                1.4\n",
      "5                5.4               3.9                1.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target\n",
       "1     0.0\n",
       "2     0.0\n",
       "3     0.0\n",
       "4     0.0\n",
       "5     0.0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X.head())\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03f216a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the data into X_train,Y_train and X_test,Y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size= 0.2,\n",
    "                                                   shuffle= True, #shuffle the data to avoid bias\n",
    "                                                   random_state= 42)\n",
    "X_train= np.asarray(X_train)\n",
    "y_train= np.asarray(y_train)\n",
    "\n",
    "X_test= np.asarray(X_test)\n",
    "y_test= np.asarray(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81f01788",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set size: 119 samples \n",
      "test set size: 30 samples\n"
     ]
    }
   ],
   "source": [
    "print(f'training set size: {X_train.shape[0]} samples \\ntest set size: {X_test.shape[0]} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a95e63d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the dataset\n",
    "scaler= Normalizer().fit(X_train) # the scaler is fitted to the training set\n",
    "normalized_X_train= scaler.transform(X_train) # the scaler is applied to the training set\n",
    "normalized_X_test= scaler.transform(X_test) # the scaler is applied to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "84fb1516",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train before Normalization\n",
      "[[5.1 3.3 1.7]\n",
      " [5.4 3.9 1.3]\n",
      " [5.6 3.  4.5]\n",
      " [4.8 3.  1.4]\n",
      " [5.  3.5 1.6]]\n",
      "\n",
      "X train after Normalization\n",
      "[[0.80850592 0.52315089 0.26950197]\n",
      " [0.79566782 0.57464898 0.19154966]\n",
      " [0.71930965 0.38534445 0.57801668]\n",
      " [0.82319321 0.51449576 0.24009802]\n",
      " [0.79245373 0.55471761 0.25358519]]\n"
     ]
    }
   ],
   "source": [
    "print('X train before Normalization')\n",
    "print(X_train[0:5])\n",
    "print('\\nX train after Normalization')\n",
    "print(normalized_X_train[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c645d12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X test before Normalization\n",
      "[[6.4 2.9 4.3]\n",
      " [5.1 3.8 1.5]\n",
      " [7.7 2.6 6.9]\n",
      " [5.7 2.6 3.5]\n",
      " [6.7 3.  5. ]]\n",
      "\n",
      "X test after Normalization\n",
      "[[0.77691418 0.35203924 0.52198921]\n",
      " [0.78047004 0.5815267  0.22955001]\n",
      " [0.72224892 0.24387626 0.64721007]\n",
      " [0.79427564 0.36230117 0.48771311]\n",
      " [0.75433425 0.3377616  0.562936  ]]\n"
     ]
    }
   ],
   "source": [
    "print('X test before Normalization')\n",
    "print(X_test[0:5])\n",
    "print('\\nX test after Normalization')\n",
    "print(normalized_X_test[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12f2a462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# knn=KNeighborsClassifier(K)\n",
    "# knn.fit(normalized_X_train, y_train)\n",
    "# y_pred_sklearn= knn.predict(normalized_X_test)\n",
    "# print(y_pred_sklearn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "074510a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': (1, 3, 5, 7, 9, 11)})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Grid search cv to find the optimal K(n_neighbors) on train data that is not normalised\n",
    "neigh = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':(1,3,5,7,9,11)}\n",
    "gs0_clf = GridSearchCV(neigh, parameters, cv = 5)\n",
    "gs0_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8dcbdf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': (1, 3, 5, 7, 9, 11)})"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Grid search cv to find the optimal K(n_neighbors) on train data that is normalised\n",
    "neigh = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':(1,3,5,7,9,11)}\n",
    "gs1_clf = GridSearchCV(neigh, parameters, cv = 5)\n",
    "gs1_clf.fit(normalized_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9d1e82d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#To select optimal K (based on K-NN model fit to not normalized train data)\n",
    "optimal_k0 = gs0_clf.best_params_.get('n_neighbors')\n",
    "print(optimal_k0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d621dec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "#To select optimal K (based on K-NN model fit to normalized train data)\n",
    "optimal_k1 = gs1_clf.best_params_.get('n_neighbors')\n",
    "print(optimal_k1)\n",
    "\n",
    "# Model fit to normaised train data suggests K= 5 which is very lower than the alternative model considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2b93fb17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 2., 1., 1., 0., 1., 1., 1., 2., 1., 0., 0., 0., 0., 1., 2.,\n",
       "       2., 1., 2., 0., 2., 0., 2., 2., 2., 2., 2., 0., 0.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the obtained optimal_k  (optimal_k1) to train our model\n",
    "knn_final = KNeighborsClassifier(n_neighbors = optimal_k1)\n",
    "knn_final.fit(normalized_X_train,y_train)\n",
    "predictions_test = knn_final.predict(normalized_X_test)\n",
    "predictions_train = knn_final.predict(normalized_X_train)\n",
    "predictions_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "94c9f3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The test and train accuracy\n",
    "test_acc = accuracy_score(y_test, predictions_test)*100\n",
    "train_acc = accuracy_score(y_train, predictions_train)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49c6aaa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86.66666666666667"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d008c4d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.63865546218487"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4f3f09c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[10,  0,  0],\n",
       "       [ 0,  7,  2],\n",
       "       [ 0,  2,  9]], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef8edbf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00        10\n",
      "         1.0       0.78      0.78      0.78         9\n",
      "         2.0       0.82      0.82      0.82        11\n",
      "\n",
      "    accuracy                           0.87        30\n",
      "   macro avg       0.87      0.87      0.87        30\n",
      "weighted avg       0.87      0.87      0.87        30\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ef30ee74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nOW, Lets try the Brute force approach to implement KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f690b2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for optimal k = 3 using brute is 90.0\n"
     ]
    }
   ],
   "source": [
    "# Run with Cross Validation: First lets try brute force on train data that is not normalised\n",
    "\n",
    "cv_scores = []\n",
    "neighbors = list(np.arange(3,50,2))\n",
    "for n in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors = n,algorithm = 'brute')\n",
    "    \n",
    "    cross_val = cross_val_score(knn,X_train,y_train,cv = 5 , scoring = 'accuracy')\n",
    "    cv_scores.append(cross_val.mean())\n",
    "    \n",
    "error = [1-x for x in cv_scores]\n",
    "optimal_n = neighbors[error.index(min(error)) ]\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors = optimal_n,algorithm = 'brute')\n",
    "knn_optimal.fit(X_train,y_train)\n",
    "pred = knn_optimal.predict(X_test)\n",
    "acc = accuracy_score(y_test,pred)*100\n",
    "print(\"The accuracy for optimal k = {0} using brute is {1}\".format(optimal_n,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ee04a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  [0.04202898550724643, 0.025362318840579712, 0.025362318840579712, 0.033695652173913127, 0.033695652173913127, 0.04202898550724643, 0.04202898550724643, 0.033695652173913127, 0.025362318840579712, 0.033695652173913127, 0.025362318840579712, 0.033695652173913127, 0.033695652173913127, 0.04202898550724632, 0.033695652173913127, 0.04202898550724632, 0.04202898550724632, 0.04202898550724632, 0.04202898550724632, 0.04202898550724632, 0.033695652173913127, 0.033695652173913127, 0.033695652173913127, 0.033695652173913127]\n",
      "Minimum Error:  0.025362318840579712\n",
      "Neighbor:  [3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]\n",
      "Error index of minimum error:  1\n",
      "neighbors value for the Error index of minimum error:  5\n",
      "The accuracy for optimal k = 5 using brute is 86.66666666666667\n"
     ]
    }
   ],
   "source": [
    "# Run with Cross Validation: First lets try brute force on NORMALISED train data\n",
    "\n",
    "cv_scores = []\n",
    "neighbors = list(np.arange(3,50,2))\n",
    "for n in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors = n,algorithm = 'brute')\n",
    "    \n",
    "    cross_val = cross_val_score(knn,normalized_X_train,y_train,cv = 5 , scoring = 'accuracy')\n",
    "    cv_scores.append(cross_val.mean())\n",
    "    \n",
    "error = [1-x for x in cv_scores]\n",
    "optimal_n = neighbors[error.index(min(error)) ]\n",
    "#print(\"Error: \", error)\n",
    "#print(\"Minimum Error: \", min(error))\n",
    "#print(\"Neighbor: \", neighbors)\n",
    "#print(\"Error index of minimum error: \", error.index(min(error)))\n",
    "#print(\"neighbors value for the Error index of minimum error: \", optimal_n)\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors = optimal_n,algorithm = 'brute')\n",
    "knn_optimal.fit(normalized_X_train,y_train)\n",
    "pred = knn_optimal.predict(normalized_X_test)\n",
    "acc = accuracy_score(y_test,pred)*100\n",
    "print(\"The accuracy for optimal k = {0} using brute is {1}\".format(optimal_n,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c495bddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# print(np.array_equal(y_test,pred)) #Accuracy is 86.67% only, and thus predictions for train data do not match well with the observed labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b19c225",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a356754a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5e80585f",
   "metadata": {},
   "source": [
    "# Now Lets change the train to test data ratio and rerun the models\n",
    "## for non-normalised as well as normalised data:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a44b1d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "# Storing the data and labels into \"X\" and \"y\" varaibles\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "# from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle= True, random_state=42)\n",
    "#from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# We “assumed” k(the number of neighbors i.e. n_neighbors)  = 3. It can also be 5, 7 … 10\n",
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "# Training or fitting the model with the train data\n",
    "model.fit(X_train,y_train)\n",
    "model.predict(X_test)\n",
    "model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "97b26595",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': (1, 3, 5, 7, 9, 11)})"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Grid search cv to find the optimal K(n_neighbors) on train data that is not normalised\n",
    "neigh00 = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':(1,3,5,7,9,11)}\n",
    "gs00_clf = GridSearchCV(neigh00, parameters, cv = 5)\n",
    "gs00_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e3806de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "#To select optimal K (based on K-NN model fit to not normalized train data)\n",
    "optimal_k00 = gs00_clf.best_params_.get('n_neighbors')\n",
    "print(optimal_k00)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6e802615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 2, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the obtained optimal_k to train our model\n",
    "knn_final00 = KNeighborsClassifier(n_neighbors = optimal_k00)\n",
    "knn_final00.fit(X_train,y_train)\n",
    "predictions_test00 = knn_final00.predict(X_test)\n",
    "predictions_train00 = knn_final00.predict(X_train)\n",
    "predictions_test00"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f83c0e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#The test and train accuracy\n",
    "test_acc00 = accuracy_score(y_test, predictions_test00)*100\n",
    "train_acc00 = accuracy_score(y_train, predictions_train00)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "25f2b8fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98.0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc00  # Ran for learning purpose only' Even with K=1, it gives 98% accuracy. \n",
    "# But what purpose does a K-NN model with K=1 serve?\n",
    "# For a very low value of k (suppose k=1), the model overfits on the training data,\n",
    "# which leads to a high error rate on the validation set.\n",
    "#On the other hand, for a high value of k, the model performs poorly on both train and validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "2273f9f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.94      1.00      0.97        15\n",
      "           2       1.00      0.94      0.97        16\n",
      "\n",
      "    accuracy                           0.98        50\n",
      "   macro avg       0.98      0.98      0.98        50\n",
      "weighted avg       0.98      0.98      0.98        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_test00))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "493169f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy for optimal k = 5 using brute is 98.0\n"
     ]
    }
   ],
   "source": [
    "# Run with Cross Validation: First lets try brute force on train data that is not normalised\n",
    "\n",
    "cv_scores = []\n",
    "neighbors = list(np.arange(3,50,2))\n",
    "for n in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors = n,algorithm = 'brute')\n",
    "    \n",
    "    cross_val = cross_val_score(knn,X_train,y_train,cv = 5 , scoring = 'accuracy')\n",
    "    cv_scores.append(cross_val.mean())\n",
    "    \n",
    "error = [1-x for x in cv_scores]\n",
    "optimal_n = neighbors[error.index(min(error)) ]\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors = optimal_n,algorithm = 'brute')\n",
    "knn_optimal.fit(X_train,y_train)\n",
    "pred = knn_optimal.predict(X_test)\n",
    "acc = accuracy_score(y_test,pred)*100\n",
    "print(\"The accuracy for optimal k = {0} using brute is {1}\".format(optimal_n,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8486e5d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets normalise the data and rerun the knn model with GridSearchCV\n",
    "\n",
    "# Normalize the dataset\n",
    "scaler= Normalizer().fit(X_train) # the scaler is fitted to the training set\n",
    "normalized_X_train= scaler.transform(X_train) # the scaler is applied to the training set\n",
    "normalized_X_test= scaler.transform(X_test) # the scaler is applied to the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a1b74f5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': (1, 3, 5, 7, 9, 11)})"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using Grid search cv to find the optimal K(n_neighbors) on train data that is normalised\n",
    "neigh01 = KNeighborsClassifier()\n",
    "parameters = {'n_neighbors':(1,3,5,7,9,11)}\n",
    "gs01_clf = GridSearchCV(neigh01, parameters, cv = 5)\n",
    "gs01_clf.fit(normalized_X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "8f708d7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "#To select optimal K (based on K-NN model fit to normalized train data)\n",
    "optimal_k01 = gs01_clf.best_params_.get('n_neighbors')\n",
    "print(optimal_k01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "25d432d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 2, 1, 1, 0, 1, 2, 1, 1, 2, 0, 0, 0, 0, 1, 2, 1, 1, 2, 0, 2,\n",
       "       0, 2, 1, 2, 2, 2, 0, 0, 0, 0, 1, 0, 0, 2, 1, 0, 0, 0, 2, 1, 1, 0,\n",
       "       0, 1, 1, 2, 1, 2])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the obtained optimal_k to train our model\n",
    "knn_final01 = KNeighborsClassifier(n_neighbors = optimal_k01)\n",
    "knn_final01.fit(normalized_X_train,y_train)\n",
    "predictions_test01 = knn_final01.predict(normalized_X_test)\n",
    "predictions_train01 = knn_final01.predict(normalized_X_train)\n",
    "predictions_test01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "340ef008",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96.0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The test and train accuracy\n",
    "test_acc01 = accuracy_score(y_test, predictions_test01)*100\n",
    "train_acc01 = accuracy_score(y_train, predictions_train01)*100\n",
    "\n",
    "test_acc01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "dcbaa569",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        19\n",
      "           1       0.88      1.00      0.94        15\n",
      "           2       1.00      0.88      0.93        16\n",
      "\n",
      "    accuracy                           0.96        50\n",
      "   macro avg       0.96      0.96      0.96        50\n",
      "weighted avg       0.96      0.96      0.96        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions_test01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0e4bb151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  [0.040000000000000036, 0.040000000000000036, 0.050000000000000044, 0.030000000000000027, 0.030000000000000027, 0.030000000000000027, 0.030000000000000027, 0.030000000000000027, 0.030000000000000027, 0.030000000000000027, 0.030000000000000027, 0.040000000000000036, 0.040000000000000036, 0.040000000000000036, 0.050000000000000044, 0.050000000000000044, 0.050000000000000044, 0.050000000000000044, 0.050000000000000044, 0.050000000000000044, 0.050000000000000044, 0.040000000000000036, 0.030000000000000027, 0.10999999999999999]\n",
      "Minimum Error:  0.030000000000000027\n",
      "Neighbor:  [3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29, 31, 33, 35, 37, 39, 41, 43, 45, 47, 49]\n",
      "Error index of minimum error:  3\n",
      "neighbors value for the Error index of minimum error:  9\n",
      "The accuracy for optimal k = 9 using brute is 96.0\n"
     ]
    }
   ],
   "source": [
    "# Run with Cross Validation: First lets try brute force on NORMALISED train data\n",
    "\n",
    "cv_scores = []\n",
    "neighbors = list(np.arange(3,50,2))\n",
    "for n in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors = n,algorithm = 'brute')\n",
    "    \n",
    "    cross_val = cross_val_score(knn,normalized_X_train,y_train,cv = 5 , scoring = 'accuracy')\n",
    "    cv_scores.append(cross_val.mean())\n",
    "    \n",
    "error = [1-x for x in cv_scores]\n",
    "optimal_n = neighbors[error.index(min(error)) ]\n",
    "#print(\"Error: \", error)\n",
    "#print(\"Minimum Error: \", min(error))\n",
    "#print(\"Neighbor: \", neighbors)\n",
    "#print(\"Error index of minimum error: \", error.index(min(error)))\n",
    "#print(\"neighbors value for the Error index of minimum error: \", optimal_n)\n",
    "knn_optimal = KNeighborsClassifier(n_neighbors = optimal_n,algorithm = 'brute')\n",
    "knn_optimal.fit(normalized_X_train,y_train)\n",
    "pred = knn_optimal.predict(normalized_X_test)\n",
    "acc = accuracy_score(y_test,pred)*100\n",
    "print(\"The accuracy for optimal k = {0} using brute is {1}\".format(optimal_n,acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8a24a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7dd52aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a5716b63",
   "metadata": {},
   "source": [
    "# K-fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5607d7c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score: 1.0\n",
      "Confusion Matrix: \n",
      "[[10  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 11]]\n",
      "Accuracy Score: 0.9666666666666667\n",
      "Confusion Matrix: \n",
      "[[13  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  6]]\n",
      "Accuracy Score: 0.9666666666666667\n",
      "Confusion Matrix: \n",
      "[[12  0  0]\n",
      " [ 0 10  0]\n",
      " [ 0  1  7]]\n",
      "Accuracy Score: 0.9333333333333333\n",
      "Confusion Matrix: \n",
      "[[ 8  0  0]\n",
      " [ 0  8  2]\n",
      " [ 0  0 12]]\n",
      "Accuracy Score: 0.9666666666666667\n",
      "Confusion Matrix: \n",
      "[[ 7  0  0]\n",
      " [ 0 11  0]\n",
      " [ 0  1 11]]\n",
      "  \n",
      "Avg. of the Validation Accuracy Score: 0.9666666666666668\n"
     ]
    }
   ],
   "source": [
    "# Instantiating the K-Fold cross validation object with  K = 5 folds \n",
    "# Donot confuse this K (cross validation folds) with optimal k (the optimal_n) in above script[s])\n",
    "\n",
    "Val_acc_scores = []\n",
    "k_folds = KFold(n_splits = 5, shuffle = True, random_state = 42) # Iterating through each of the folds in K-Fold\n",
    "for train_index, val_index in k_folds.split(X):\n",
    "    \n",
    "    # Splitting the training set from the validation set for this specific fold\n",
    "    X_train, X_val = X[train_index, :], X[val_index, :]  # X is not pandas dataframe and hence X.iloc not needed\n",
    "    y_train, y_val = y[train_index], y[val_index] #  # y is not pandas dataframe and hence X.iloc not needed\n",
    "    \n",
    "    # Instantiating a KNeighborsClassifier model\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = 9) # we choose n_neighbors = 9 (optimal_n) from the above model\n",
    "    \n",
    "    # Fitting the X_train and y_train datasets to the RandomForestClassifier model\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    \n",
    "    # Getting inferential predictions for the validation dataset\n",
    "    val_preds = knn_model.predict(X_val)\n",
    "    \n",
    "    # Generating validation metrics by comparing the inferential predictions (val_preds) to the actuals (y_val)\n",
    "    val_accuracy = accuracy_score(y_val, val_preds)\n",
    "    val_confusion_matrix = confusion_matrix(y_val, val_preds)\n",
    "    \n",
    "    Val_acc_scores.append(val_accuracy)\n",
    "    \n",
    "    # Printing out the validation metrics\n",
    "    print(f'Accuracy Score: {val_accuracy}')\n",
    "    print(f'Confusion Matrix: \\n{val_confusion_matrix}')\n",
    "\n",
    "print(\"  \")\n",
    "print(f'Avg. of the Validation Accuracy Score: {np.mean(Val_acc_scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9afb07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional References:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f09cbfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference #1: An implementation that focuses on hyperparameter tuning for kNN using the Iris dataset \n",
    "# implemented from scratch with no dependencies on existing python data science libraries.\n",
    "# https://towardsdatascience.com/k-nn-on-iris-dataset-3b827f2591e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f8c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference #2: https://medium.com/@avulurivenkatasaireddy/k-nearest-neighbors-and-implementation-on-iris-data-set-f5817dd33711"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23150a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reference #3: https://deepnote.com/@ndungu/Implementing-KNN-Algorithm-on-the-Iris-Dataset-e7c16493-500c-4248-be54-9389de603f16"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
