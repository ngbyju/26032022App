{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "954bfb8a",
   "metadata": {},
   "source": [
    "# Linear , Ridge and Lasso Regression with GridSearchCV on Boston Housing Dataset\n",
    "Byju N Govindan "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d22a4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Ridge:     Ridge regression addresses some of the problems of Ordinary Least Squares by imposing a penalty on the size of the coefficients with l2 regularization.\n",
    "#Lasso:     The Lasso is a linear model that estimates sparse coefficients with l1 regularization.\n",
    "#ElasticNet: Elastic-Net is a linear regression model trained with both l1 and l2 -norm regularization of the coefficients.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75792d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# housing price dataset\n",
    "from sklearn.datasets import load_boston"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "264249db",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import requird libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "546ebe4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  \n",
       "0     15.3  396.90   4.98  \n",
       "1     17.8  396.90   9.14  \n",
       "2     17.8  392.83   4.03  \n",
       "3     18.7  394.63   2.94  \n",
       "4     18.7  396.90   5.33  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_boston()\n",
    "dataset = pd.DataFrame(df.data)\n",
    "dataset.columns = df.feature_names\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f2b52d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  Price  \n",
       "0     15.3  396.90   4.98   24.0  \n",
       "1     17.8  396.90   9.14   21.6  \n",
       "2     17.8  392.83   4.03   34.7  \n",
       "3     18.7  394.63   2.94   33.4  \n",
       "4     18.7  396.90   5.33   36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['Price'] = df.target\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d04d167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume you have dataframe named \"dataset\" loaded with multiple records and columns.\n",
    "# How will you access the independent variables (assume all but last column) and dependent variable (assume, the last column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bcb5b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Divide the dataset into independent and dependent features\n",
    "X = dataset.iloc[:, :-1] ## access the independent variables ; all rows all but the last columnin the dataframe\n",
    "y = dataset.iloc[:, -1] ## Dependent variable ; all rows of just the last column in the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "164bf723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-34.705255944524815\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lin_reg = LinearRegression()\n",
    "mse = cross_val_score(lin_reg, X, y, scoring = 'neg_mean_squared_error', cv = 10) \n",
    "# first parameter is model, then independent variable and dependent variable\n",
    "#Ideally you split the dataset to train and test dataset\n",
    "# Then only give the traindatset only for crossvalidation.\n",
    "# Here I am being lazy and just applying crossvalidation on entire dataset\n",
    "#for scoring, you may give mean squared error or negative mean squared error etc...\n",
    "\n",
    "mean_mse =np.mean(mse) # Average of all 5 cross validations\n",
    "print(mean_mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab5077e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you have  split data to train and test data, you can do prediction on test data as\n",
    "#lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06cf5d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Ridge(),\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.001, 0.01, 1, 5, 10,\n",
       "                                   20, 30, 35, 40, 45, 50, 55, 100]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV # Hyperparamter tuning\n",
    "ridge = Ridge()\n",
    "\n",
    "params = {'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}\n",
    "\n",
    "ridge_regressor = GridSearchCV(ridge, params, scoring = 'neg_mean_squared_error', cv = 10) \n",
    "ridge_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5833004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 100}\n",
      "-29.615220097335175\n"
     ]
    }
   ],
   "source": [
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50a8b6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We did ridge regression to avoid overfitting. Yet, With GridSearchCV, we got a higher mean_mse.\n",
    "#  Means Ridge regression is not doing better job than Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f407774",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4304.727397919132, tolerance: 4.0699769802197805\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5130.989301258292, tolerance: 4.11663454945055\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4710.799754639584, tolerance: 4.123618057142857\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4240.963130360648, tolerance: 3.34213498021978\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3747.8679255165566, tolerance: 3.7586257450549456\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4954.661210009472, tolerance: 3.4413134593406594\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5218.454961823944, tolerance: 4.189029157894736\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2527.9240392092915, tolerance: 3.382079664473684\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4752.966024812728, tolerance: 3.73586051754386\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5161.625201348237, tolerance: 4.100420313596492\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Lasso(),\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.001, 0.01, 1, 5, 10,\n",
       "                                   20, 30, 35, 40, 45, 50, 55, 100]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lets try Lasso now.  #Lasso Regression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV # Hyperparamter tuning\n",
    "lasso = Lasso()\n",
    "\n",
    "params = {'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}\n",
    "\n",
    "lasso_regressor = GridSearchCV(lasso, params, scoring = 'neg_mean_squared_error', cv = 10) \n",
    "lasso_regressor.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f7e0676e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n",
      "-34.45554381307912\n"
     ]
    }
   ],
   "source": [
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b8121f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lasso regression also did not yield us a better fit than Linear regression. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5ad2fc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Understand the mean_mse value must go towards zero to have the best model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74e519cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now lets split dataset into train and test datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5d9d7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25.473094575615903\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lin_reg = LinearRegression()\n",
    "mse = cross_val_score(lin_reg, X_train, y_train, scoring = 'neg_mean_squared_error', cv = 10) \n",
    "mean_mse =np.mean(mse) # Average of all 5 cross validations\n",
    "print(mean_mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1b8667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2387.751964353778, tolerance: 2.7116020131147542\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2842.324993692705, tolerance: 2.5569594885245905\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3341.716349309617, tolerance: 2.8039389377049178\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2828.9522476972306, tolerance: 2.6777008524590165\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3212.0526411232336, tolerance: 2.5642502819672135\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2896.7253735868244, tolerance: 2.583982937704918\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3493.850893362145, tolerance: 2.7500631278688528\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1778.855517476246, tolerance: 2.7534481508196724\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3471.91231634435, tolerance: 2.762774118032787\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3168.2475475744295, tolerance: 2.720463441176471\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Lasso(),\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.001, 0.01, 1, 5, 10,\n",
       "                                   20, 30, 35, 40, 45, 50, 55, 100]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Lasso Regression with train_test_split dataset\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV # Hyperparamter tuning\n",
    "lin_regressor = LinearRegression()\n",
    "\n",
    "params = {'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}\n",
    "\n",
    "lin_regressor = GridSearchCV(lasso, params, scoring = 'neg_mean_squared_error', cv = 10) \n",
    "lin_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e66bc1fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-22.985015840300843"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lin_regressor.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28b3adb4",
   "metadata": {},
   "source": [
    "# What does score method output in linear regression?\n",
    "\n",
    "#Return the coefficient of determination of the prediction, the R -Square.\n",
    "\n",
    "The coefficient of determination is defined as [1 - (u/v)],  where u is the residual sum of squares ((y_true - y_pred)** 2).sum() and v is the total sum of squares ((y_true - y_true.mean()) ** 2).sum(). The best possible score is 1.0 and it can be negative (because the model can be arbitrarily worse). \n",
    "\n",
    "A constant model that always predicts the expected value of y, disregarding the input features, would get a score of 0.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e677769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-08}\n",
      "-25.473094572833237\n"
     ]
    }
   ],
   "source": [
    "print(lin_regressor.best_params_)\n",
    "print(lin_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0efa6e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.53469457, 36.61870038, 15.63751051, 25.50144953, 18.70967356,\n",
       "       23.16471553, 17.31011033, 14.0773636 , 23.01064349, 20.5422349 ,\n",
       "       24.91632311, 18.41098048, -6.52079694, 21.83372577, 19.14903066,\n",
       "       26.05873213, 20.30232607,  5.74943563, 40.33137805, 17.4579146 ,\n",
       "       27.47486675, 30.21707564, 10.80555628, 23.8772175 , 17.99492226,\n",
       "       16.02608761, 23.26828778, 14.36825218, 22.38116931, 19.30920694,\n",
       "       22.17284558, 25.05925451, 25.13780726, 18.46730239, 16.60405678,\n",
       "       17.46564111, 30.71367735, 20.05106816, 23.98977653, 24.94322399,\n",
       "       13.97945361, 31.64706961, 42.48057194, 17.70042803, 26.92507866,\n",
       "       17.15897728, 13.68918092, 26.14924236, 20.27823036, 29.99003508,\n",
       "       21.21260346, 34.03649177, 15.41837559, 25.95781066, 39.13897287,\n",
       "       22.9611842 , 18.8031058 , 33.07865363, 24.74384153, 12.83640948,\n",
       "       22.41963416, 30.64804998, 31.5956712 , 16.34088222, 20.95043064,\n",
       "       16.70145827, 20.23215651, 26.1437865 , 31.12160899, 11.8976278 ,\n",
       "       20.45432398, 27.4835633 , 10.8903424 , 16.7770726 , 24.02593685,\n",
       "        5.44691806, 21.35152324, 41.27267162, 18.1344764 ,  9.80120976,\n",
       "       21.24024336, 13.02644929, 21.8019838 ,  9.48201753, 22.99183854,\n",
       "       31.90465609, 18.95594735, 25.48515047, 29.49687006, 20.07282542,\n",
       "       25.56160622,  5.59584378, 20.18410911, 15.08773307, 14.34562143,\n",
       "       20.85155416, 24.80149375, -0.19785448, 13.57649025, 15.64401642,\n",
       "       22.03765767, 24.70314457, 10.86409086, 19.60231095, 23.73429165,\n",
       "       12.08082148, 18.40997922, 25.43661607, 20.76506674, 24.68588256,\n",
       "        7.49958371, 18.9301563 , 21.70801804, 27.14350576, 31.93765197,\n",
       "       15.19483602, 34.01357422, 12.85763104, 21.06646201, 28.5847004 ,\n",
       "       15.77437529, 24.77512509,  3.646557  , 23.91169581, 25.82292936,\n",
       "       23.03339689, 25.35158352, 33.05655441, 20.65930517, 38.18917344,\n",
       "       14.04714268, 25.26034472, 17.6138724 , 20.60883747,  9.85255495,\n",
       "       21.06756927, 22.20145617, 32.29202764, 31.57638337, 15.29265948,\n",
       "       16.71002364, 29.10550927, 25.17762314, 16.88159178,  6.32621883,\n",
       "       26.70210233, 23.35258559, 17.24168203, 13.228157  , 39.49907495,\n",
       "       16.5352859 , 18.14635927, 25.06620441, 23.70640224, 22.20167769,\n",
       "       21.22272365, 16.89825901, 23.1551832 , 28.69699824,  6.65526496,\n",
       "       23.98399955, 17.21004549, 21.05744274, 25.01734607, 27.65461885,\n",
       "       20.70205838, 40.38214892])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you have  split data to train and test data, you can do prediction on test data as\n",
    "lin_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ca8396d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Ridge(),\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.001, 0.01, 1, 5, 10,\n",
       "                                   20, 30, 35, 40, 45, 50, 55, 100]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Ridge Regression\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV # Hyperparamter tuning\n",
    "ridge = Ridge()\n",
    "\n",
    "params = {'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}\n",
    "\n",
    "ridge_regressor = GridSearchCV(ridge, params, scoring = 'neg_mean_squared_error', cv = 10) \n",
    "ridge_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6c50e8ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n",
      "-25.472067363367756\n"
     ]
    }
   ],
   "source": [
    "print(ridge_regressor.best_params_)\n",
    "print(ridge_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9db09037",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.52859307, 36.61391924, 15.62446448, 25.49794339, 18.71651761,\n",
       "       23.14663912, 17.30883131, 14.07475692, 22.99166445, 20.54553336,\n",
       "       24.90263157, 18.40809393, -6.52400321, 21.82072889, 19.14851303,\n",
       "       26.0555678 , 20.29340873,  5.74691746, 40.3292144 , 17.46378034,\n",
       "       27.47957205, 30.21416421, 10.80664516, 23.88716488, 18.00126984,\n",
       "       16.01130598, 23.25744349, 14.37364861, 22.3671398 , 19.31468367,\n",
       "       22.16363415, 25.06329806, 25.13823978, 18.48393229, 16.58826798,\n",
       "       17.49443878, 30.7138197 , 20.06344919, 23.98208654, 24.9392659 ,\n",
       "       13.98171769, 31.64424572, 42.47600973, 17.69471466, 26.92334773,\n",
       "       17.1620035 , 13.6905632 , 26.145616  , 20.26656429, 29.99670048,\n",
       "       21.21064505, 34.03300557, 15.42093099, 25.95970143, 39.14516313,\n",
       "       22.95869281, 18.81261673, 33.07917693, 24.74240933, 12.83096178,\n",
       "       22.42715454, 30.65664806, 31.59958777, 16.35222889, 20.96015475,\n",
       "       16.68403699, 20.23389533, 26.14354346, 31.12585147, 11.90302348,\n",
       "       20.45109263, 27.46958133, 10.89755717, 16.79681713, 24.01250846,\n",
       "        5.44645417, 21.34784167, 41.26752741, 18.13170091,  9.78541651,\n",
       "       21.23670746, 13.00801021, 21.80389016,  9.48192028, 22.9891692 ,\n",
       "       31.8989435 , 18.96346652, 25.49171022, 29.49086694, 20.07366315,\n",
       "       25.56220367,  5.59355694, 20.18693075, 15.09000395, 14.35405658,\n",
       "       20.85478081, 24.79424338, -0.21946712, 13.5859797 , 15.62737036,\n",
       "       22.03445812, 24.69133724, 10.85151304, 19.61436039, 23.73582709,\n",
       "       12.06813566, 18.41749969, 25.44869273, 20.78159819, 24.69318085,\n",
       "        7.50484425, 18.91465693, 21.72567149, 27.14200965, 31.93243807,\n",
       "       15.20142336, 34.01094141, 12.86221047, 21.07368996, 28.58334938,\n",
       "       15.77007631, 24.78111478,  3.65107257, 23.90711146, 25.82792884,\n",
       "       23.03786781, 25.35874826, 33.05326316, 20.68744673, 38.18127409,\n",
       "       14.03406738, 25.26164047, 17.6176464 , 20.59966964,  9.87756487,\n",
       "       21.05637121, 22.21461852, 32.29312098, 31.57395002, 15.29657149,\n",
       "       16.71588555, 29.10259292, 25.1703922 , 16.86494322,  6.32932136,\n",
       "       26.68776841, 23.37961384, 17.25125102, 13.22924135, 39.49407945,\n",
       "       16.54176611, 18.15737635, 25.07169795, 23.70262643, 22.19971206,\n",
       "       21.23926077, 16.88861638, 23.17536326, 28.70534889,  6.66111129,\n",
       "       23.98188285, 17.21082949, 21.05931422, 25.02120712, 27.66542978,\n",
       "       20.70837431, 40.39262145])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you have  split data to train and test data, you can do prediction on test data as\n",
    "ridge_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "91eebe48",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2387.751964353778, tolerance: 2.7116020131147542\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2842.324993692705, tolerance: 2.5569594885245905\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3341.716349309617, tolerance: 2.8039389377049178\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2828.9522476972306, tolerance: 2.6777008524590165\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3212.0526411232336, tolerance: 2.5642502819672135\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2896.7253735868244, tolerance: 2.583982937704918\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3493.850893362145, tolerance: 2.7500631278688528\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1778.855517476246, tolerance: 2.7534481508196724\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3471.91231634435, tolerance: 2.762774118032787\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "C:\\Users\\ngbyju\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 3168.2475475744295, tolerance: 2.720463441176471\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=Lasso(),\n",
       "             param_grid={'alpha': [1e-15, 1e-10, 1e-08, 0.001, 0.01, 1, 5, 10,\n",
       "                                   20, 30, 35, 40, 45, 50, 55, 100]},\n",
       "             scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " #Lasso Regression with train_test_split dataset\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV # Hyperparamter tuning\n",
    "lasso = Lasso()\n",
    "\n",
    "params = {'alpha': [1e-15, 1e-10, 1e-8, 1e-3, 1e-2, 1, 5, 10, 20, 30, 35, 40, 45, 50, 55, 100]}\n",
    "\n",
    "lasso_regressor = GridSearchCV(lasso, params, scoring = 'neg_mean_squared_error', cv = 10) \n",
    "lasso_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a10032d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-08}\n",
      "-25.473094572833237\n"
     ]
    }
   ],
   "source": [
    "print(lasso_regressor.best_params_)\n",
    "print(lasso_regressor.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "97a23cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([28.53469457, 36.61870038, 15.63751051, 25.50144953, 18.70967356,\n",
       "       23.16471553, 17.31011033, 14.0773636 , 23.01064349, 20.5422349 ,\n",
       "       24.91632311, 18.41098048, -6.52079694, 21.83372577, 19.14903066,\n",
       "       26.05873213, 20.30232607,  5.74943563, 40.33137805, 17.4579146 ,\n",
       "       27.47486675, 30.21707564, 10.80555628, 23.8772175 , 17.99492226,\n",
       "       16.02608761, 23.26828778, 14.36825218, 22.38116931, 19.30920694,\n",
       "       22.17284558, 25.05925451, 25.13780726, 18.46730239, 16.60405678,\n",
       "       17.46564111, 30.71367735, 20.05106816, 23.98977653, 24.94322399,\n",
       "       13.97945361, 31.64706961, 42.48057194, 17.70042803, 26.92507866,\n",
       "       17.15897728, 13.68918092, 26.14924236, 20.27823036, 29.99003508,\n",
       "       21.21260346, 34.03649177, 15.41837559, 25.95781066, 39.13897287,\n",
       "       22.9611842 , 18.8031058 , 33.07865363, 24.74384153, 12.83640948,\n",
       "       22.41963416, 30.64804998, 31.5956712 , 16.34088222, 20.95043064,\n",
       "       16.70145827, 20.23215651, 26.1437865 , 31.12160899, 11.8976278 ,\n",
       "       20.45432398, 27.4835633 , 10.8903424 , 16.7770726 , 24.02593685,\n",
       "        5.44691806, 21.35152324, 41.27267162, 18.1344764 ,  9.80120976,\n",
       "       21.24024336, 13.02644929, 21.8019838 ,  9.48201753, 22.99183854,\n",
       "       31.90465609, 18.95594735, 25.48515047, 29.49687006, 20.07282542,\n",
       "       25.56160622,  5.59584378, 20.18410911, 15.08773307, 14.34562143,\n",
       "       20.85155416, 24.80149375, -0.19785448, 13.57649025, 15.64401642,\n",
       "       22.03765767, 24.70314457, 10.86409086, 19.60231095, 23.73429165,\n",
       "       12.08082148, 18.40997922, 25.43661607, 20.76506674, 24.68588256,\n",
       "        7.49958371, 18.9301563 , 21.70801804, 27.14350576, 31.93765197,\n",
       "       15.19483602, 34.01357422, 12.85763104, 21.06646201, 28.5847004 ,\n",
       "       15.77437529, 24.77512509,  3.646557  , 23.91169581, 25.82292936,\n",
       "       23.03339689, 25.35158352, 33.05655441, 20.65930517, 38.18917344,\n",
       "       14.04714268, 25.26034472, 17.6138724 , 20.60883747,  9.85255495,\n",
       "       21.06756927, 22.20145617, 32.29202764, 31.57638337, 15.29265948,\n",
       "       16.71002364, 29.10550927, 25.17762314, 16.88159178,  6.32621883,\n",
       "       26.70210233, 23.35258559, 17.24168203, 13.228157  , 39.49907495,\n",
       "       16.5352859 , 18.14635927, 25.06620441, 23.70640224, 22.20167769,\n",
       "       21.22272365, 16.89825901, 23.1551832 , 28.69699824,  6.65526496,\n",
       "       23.98399955, 17.21004549, 21.05744274, 25.01734607, 27.65461885,\n",
       "       20.70205838, 40.38214892])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you have  split data to train and test data, you can do prediction on test data as\n",
    "lasso_regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7d220780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6709558959121944\n"
     ]
    }
   ],
   "source": [
    "y_pred = lasso_regressor.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score_lasso = r2_score(y_pred, y_test)\n",
    "print(r2_score_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ae2ee644",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.670874325753307\n"
     ]
    }
   ],
   "source": [
    "y_pred = ridge_regressor.predict(X_test)\n",
    "r2_score_ridge = r2_score(y_pred, y_test)\n",
    "print(r2_score_ridge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "05a462d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6709558959121944\n"
     ]
    }
   ],
   "source": [
    "y_pred = lin_regressor.predict(X_test)\n",
    "r2_score_linear = r2_score(y_pred, y_test)\n",
    "print(r2_score_linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfb566b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
